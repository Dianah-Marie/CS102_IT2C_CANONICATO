"title","author","subject","abstract","date"
"rethinking autoencoders for medical anomaly detection from a theoretical perspective","yu cai, hao chen, kwang-ting cheng","machine learning","medical anomaly detection aims to identify abnormal findings using only normal training data, playing a crucial role in health screening and recognizing rare diseases. reconstruction-based methods, particularly those utilizing autoencoders (aes), are dominant in this field. they work under the assumption that aes trained on only normal data cannot reconstruct unseen abnormal regions well, thereby enabling the anomaly detection based on reconstruction errors. however, this assumption does not always hold due to the mismatch between the reconstruction training objective and the anomaly detection task objective, rendering these methods theoretically unsound. this study focuses on providing a theoretical foundation for ae-based reconstruction methods in anomaly detection. by leveraging information theory, we elucidate the principles of these methods and reveal that the key to improving ae in anomaly detection lies in minimizing the information entropy of latent vectors. experiments on four datasets with two image modalities validate the effectiveness of our theory. to the best of our knowledge, this is the first effort to theoretically clarify the principles and design philosophy of ae for anomaly detection. code will be available upon acceptance.",2024-03-14
"research and teaching in physics at the university of franche-comté 1845-1970","john m. dudley, jeanne magnin, luc froehly, jerome salvi, pierre verschueren, maxime jacquot","history and philosophy of physics","recently uncovered archives at the university of franche-comté in besançon (france) reveal a rich history of research and teaching in physics since the faculty of science was first established in 1845. here, we describe a selection of notable activities conducted by the named chairs of physics during the period 1845-1970. we uncover a long tradition of major contributions to physics education and research, including the production of highly regarded physics textbooks that were widely used in europe, as well as pioneering contributions to electron diffraction and microscopy, fourier optics, and holography. these discoveries yield valuable insights into the historical development of physics research in france, and show how even a small provincial university was able to stay up-to-date with international developments across several areas of physics.",2024-03-14
"gr as a classical spin-2 theory?","niels linnemann, chris smeenk, mark robert baker","history and philosophy of physics","the self-interaction spin-2 approach to general relativity (gr) has been extremely influential in the particle physics community. leaving no doubt regarding its heuristic value, we argue that a view of the metric field of gr as nothing but a stand-in for a self-coupling field in flat spacetime runs into a dilemma: either the view is physically incomplete in so far as it requires recourse to gr after all, or it leads to an absurd multiplication of alternative viewpoints on gr rendering any understanding of the metric field as nothing but a spin-2 field in flat spacetime unjustified.",2024-03-13
"what would plato say? concepts and notions from greek philosophy applied to gamification mechanics for a meaningful and ethical gamification","kostas karpouzis","human-computer interaction","gamification, the integration of game mechanics in non-game settings, has become increasingly prevalent in various digital platforms; however, its ethical and societal impacts are often overlooked. this paper delves into how platonic and aristotelian philosophies can provide a critical framework for understanding and evaluating the ethical dimensions of gamification. plato's allegory of the cave and theory of forms are used to analyse the perception of reality in gamified environments, questioning their authenticity and the value of virtual achievements, while aristotle's virtue ethics, with its emphasis on moderation, virtue, and eudaimonia (true and full happiness), can help assess how gamification influences user behaviour and ethical decision-making. the paper critically examines various gamification elements, such as the hero's journey, altruistic actions, badge levels, and user autonomy, through these philosophical lenses, and addresses the ethical responsibilities of gamification designers, advocating for a balanced approach that prioritizes user well-being and ethical development over commercial interests. by bridging ancient philosophical insights with modern digital culture, this research contributes to a deeper understanding of the ethical implications of gamification, emphasizing the need for responsible and virtuous design in digital applications.",2024-03-12
"navigating the quantum divide(s)","a. ayda gercek, zeki c. seskir","physics and society","this article explores the possible divides resulting from the introduction of emerging quantum technologies (qt) to society. it provides the multidirectional impacts of qt on science, technology, geopolitics, and societal structures. we aim to challenge the idea of a singular ""quantum divide"" by presenting a more comprehensive perspective. to complement the existing literature on the quantum divide, we propose four distinct divides that could result from the emergence of qt. firstly, we examine the ""quantum divide in science"", representing the paradigmatic gap among scientists and inequalities in access to knowledge/resources within research communities. we suggest the ""quantum divide in technologies through path-dependency"" as the second possible divide, examining the adoption processes of certain technologies to be developed by nations, firms, and research communities. the discussion extends internationally, focusing on the ""quantum divide between countries,"" by dealing with the reasons and outcomes of the adoption processes between countries of different development levels (economically, industrially, and technologically). as the final divide, we put forth our perspective on the ""quantum divide within societies"", one of the most explored ones in the literature, addressing societal implications. for each type of the divide, we propose several directions to navigate them, some complementary, some incompatible. finally, we discuss the interconnectedness and distinctness of different types of divides and how they impact the directions to navigate them. this study serves as a guidance for those interested in a more in-depth investigation of the concept of quantum divide, possible directions of navigating the divides, and how the introduction of qt might affect the innovation ecosystems by impacting the scientific, technological, international, and societal institutions.",2024-03-12
"minkunext: point cloud-based large-scale place recognition using 3d sparse convolutions","j.j. cabrera, a. santo, a. gil, c. viegas, l. payá","computer vision and pattern recognition","this paper presents minkunext, an effective and efficient architecture for place-recognition from point clouds entirely based on the new 3d minknext block, a residual block composed of 3d sparse convolutions that follows the philosophy established by recent transformers but purely using simple 3d convolutions. feature extraction is performed at different scales by a u-net encoder-decoder network and the feature aggregation of those features into a single descriptor is carried out by a generalized mean pooling (gem). the proposed architecture demonstrates that it is possible to surpass the current state-of-the-art by only relying on conventional 3d sparse convolutions without making use of more complex and sophisticated proposals such as transformers, attention-layers or deformable convolutions. a thorough assessment of the proposal has been carried out using the oxford robotcar and the in-house datasets. as a result, minkunext proves to outperform other methods in the state-of-the-art.",2024-03-12
"mammoth: massively multilingual modular open translation @ helsinki","timothee mickus, stig-arne grönroos, joseph attieh, michele boggia, ona de gibert, shaoxiong ji, niki andreas lopi, alessandro raganato, raúl vázquez, jörg tiedemann","computation and language","nlp in the age of monolithic large language models is approaching its limits in terms of size and information that can be handled. the trend goes to modularization, a necessary step into the direction of designing smaller sub-networks and components with specialized functionality. in this paper, we present the mammoth toolkit: a framework designed for training massively multilingual modular machine translation systems at scale, initially derived from opennmt-py and then adapted to ensure efficient training across computation clusters. we showcase its efficiency across clusters of a100 and v100 nvidia gpus, and discuss our design philosophy and plans for future information. the toolkit is publicly available online.",2024-03-12
"the dawn of ai-native eda: promises and challenges of large circuit models","lei chen (1), yiqi chen (2), zhufei chu (3), wenji fang (4), tsung-yi ho (5), yu huang (6), sadaf khan (5), min li (1), xingquan li (7), yun liang (2), yibo lin (2), jinwei liu (5), yi liu (5), guojie luo (2), zhengyuan shi (5), guangyu sun (2), dimitrios tsaras (1), runsheng wang (2), ziyi wang (5), xinming wei (2), zhiyao xie (4), qiang xu (5), chenhao xue (2), evangeline f.y. young (5), bei yu (5), mingxuan yuan (1), haoyi zhang (2), zuodong zhang (2), yuxiang zhao (2), hui-ling zhen (1), ziyang zheng (5), binwu zhu (5), keren zhu (5), sunan zou (2) ((1) huawei noah's ark lab, (2) peking university, (3) ningbo university, (4) hong kong university of science and technology, (5) the chinese university of hong kong, (6) huawei hisilicon, (7) peng cheng laboratory)","hardware architecture","within the electronic design automation (eda) domain, ai-driven solutions have emerged as formidable tools, yet they typically augment rather than redefine existing methodologies. these solutions often repurpose deep learning models from other domains, such as vision, text, and graph analytics, applying them to circuit design without tailoring to the unique complexities of electronic circuits. such an ai4eda approach falls short of achieving a holistic design synthesis and understanding, overlooking the intricate interplay of electrical, logical, and physical facets of circuit data. this perspective paper argues for a paradigm shift from ai4eda towards ai-native eda, integrating ai at the core of the design process. pivotal to this vision is the development of a multimodal circuit representation learning technique, poised to provide a comprehensive understanding by harmonizing and extracting insights from varied data sources, such as functional specifications, rtl designs, circuit netlists, and physical layouts. we champion the creation of large circuit models (lcms) that are inherently multimodal, crafted to decode and express the rich semantics and structures of circuit data, thus fostering more resilient, efficient, and inventive design methodologies. embracing this ai-native philosophy, we foresee a trajectory that transcends the current innovation plateau in eda, igniting a profound shift-left in electronic design methodology. the envisioned advancements herald not just an evolution of existing eda tools but a revolution, giving rise to novel instruments of design-tools that promise to radically enhance design productivity and inaugurate a new epoch where the optimization of circuit performance, power, and area (ppa) is achieved not incrementally, but through leaps that redefine the benchmarks of electronic systems' capabilities.",2024-03-12
"on the stochastics of human and artificial creativity","solve sæbø, helge brovold","artificial intelligence","what constitutes human creativity, and is it possible for computers to exhibit genuine creativity? we argue that achieving human-level intelligence in computers, or so-called artificial general intelligence, necessitates attaining also human-level creativity. we contribute to this discussion by developing a statistical representation of human creativity, incorporating prior insights from stochastic theory, psychology, philosophy, neuroscience, and chaos theory. this highlights the stochastic nature of the human creative process, which includes both a bias guided, random proposal step, and an evaluation step depending on a flexible or transformable bias structure. the acquired representation of human creativity is subsequently used to assess the creativity levels of various contemporary ai systems. our analysis includes modern ai algorithms such as reinforcement learning, diffusion models, and large language models, addressing to what extent they measure up to human level creativity. we conclude that these technologies currently lack the capability for autonomous creative action at a human level.",2024-03-03
"height filtrations and base loci on flag bundles over a curve","yangyu fan, wenbin luo, binggang qu","number theory","let $k$ be an algebraically closed field of characteristic zero. let $c/k$ be a projective smooth curve with function field $k=k(c)$ and $g/k$ be a connected reductive group. let $f$ be a principal $g$-bundle on $c$. let $p \subseteq g$ be a parabolic subgroup and $\lambda: p \longrightarrow g$ be a strictly anti-dominant character. then $f/p \longrightarrow c$ is a flag bundle and $\mathcal{l}_\lambda=f \times_p k_\lambda$ on $f/p$ is a relatively ample line bundle. let $h_{\mathcal{l}_\lambda}$ be the height function on $x=(f/p)_k$ induced by $\mathcal{l}_\lambda$. we compute its height filtration and successive minima: the height filtration is given by a bruhat decomposition and successive minima are given by slopes. an interesting application is that, in this case, zhang's inequality on successive minima can be enhanced into an equality. this is proved from the convex geometry point of view. let $f \in n^1(f/p)$ be the numerical class of a vertical fiber. we also compute the augmented base loci $\mathrm{b}_+(\mathcal{l}_\lambda-tf)$ for any $t \in \mathbb{r}$ and it turns out that they are almost the same as the height filtration, which accords with the philosophy in arakelov geometry that the positivity of the line bundle $\mathcal{l}_\lambda$ is equivalent to the positivity of its induced height function $h_{\mathcal{l}_\lambda}$. as a corollary, we compute the $k$-th movable cones of flag bundles over curves for all $k$.",2024-03-11
"from s-matrix theory to strings: scattering data and the commitment to non-arbitrariness","robert van leeuwen","history and philosophy of physics","the early history of string theory is marked by a shift from strong interaction physics to quantum gravity. the first string models and associated theoretical framework were formulated in the late 1960s and early 1970s in the context of the s-matrix program for the strong interactions. in the mid-1970s, the models were reinterpreted as a potential theory unifying the four fundamental forces. this paper provides a historical analysis of how string theory was developed out of s-matrix physics, aiming to clarify how modern string theory, as a theory detached from experimental data, grew out of an s-matrix program that was strongly dependent upon observable quantities. surprisingly, the theoretical practice of physicists already turned away from experiment before string theory was recast as a potential unified quantum gravity theory. with the formulation of dual resonance models (the ""hadronic string theory""), physicists were able to determine almost all of the models' parameters on the basis of theoretical reasoning. it was this commitment to ""non-arbitrariness"", i.e., a lack of free parameters in the theory, that initially drove string theorists away from experimental input, and not the practical inaccessibility of experimental data in the context of quantum gravity physics. this is an important observation when assessing the role of experimental data in string theory.",2024-03-11
"unexpected quantum indeterminacy","andrea oldofredi","history and philosophy of physics","recent philosophical discussions about metaphysical indeterminacy have been substantiated with the idea that quantum mechanics, one of the most successful physical theories in the history of science, provides explicit instances of worldly indefiniteness. against this background, several philosophers underline that there are alternative formulations of quantum theory in which such indeterminacy has no room and plays no role. a typical example is bohmian mechanics in virtue of its clear particle ontology. contrary to these latter claims, this paper aims at showing that different pilot-wave theories do in fact instantiate diverse forms of metaphysical indeterminacy. namely, i argue that there are various questions about worldly states of affairs that cannot be determined by looking exclusively at their ontologies and dynamical laws. moreover, it will be claimed that bohmian mechanics generates a new form of modal indeterminacy. finally, it will be concluded that ontological clarity and indeterminacy are not mutually exclusive, i.e., the two can coexist in the same theory.",2024-03-11
"ac-eval: evaluating ancient chinese language understanding in large language models","yuting wei, yuanxing xu, xinru wei, simin yang, yangfu zhu, yuqing li, di liu, bin wu","computation and language","given the importance of ancient chinese in capturing the essence of rich historical and cultural heritage, the rapid advancements in large language models (llms) necessitate benchmarks that can effectively evaluate their understanding of ancient contexts. to meet this need, we present ac-eval, an innovative benchmark designed to assess the advanced knowledge and reasoning capabilities of llms within the context of ancient chinese. ac-eval is structured across three levels of difficulty reflecting different facets of language comprehension: general historical knowledge, short text understanding, and long text comprehension. the benchmark comprises 13 tasks, spanning historical facts, geography, social customs, art, philosophy, classical poetry and prose, providing a comprehensive assessment framework. our extensive evaluation of top-performing llms, tailored for both english and chinese, reveals a substantial potential for enhancing ancient text comprehension. by highlighting the strengths and weaknesses of llms, ac-eval aims to promote their development and application forward in the realms of ancient chinese language education and scholarly research. the ac-eval data and evaluation code are available at this https url.",2024-03-11
"bernardo dessau, fisico, scienziato, maestro, da bologna a perugia tra i marosi del secolo breve","giovanni carlotti (university of perugia, italia)","history and philosophy of physics","seventy-five years ago, bernardo dessau passed away. he had been the sole professor of physics at the university of perugia for thirty years. with this brief contribution we intend to repay a debt of gratitude, first of all because his scientific merits were probably underestimated, having spent the first fifteen years of his career under the shadow of the great augusto righi in bologna, where he also witnessed meetings with the young marconi. he was then relegated to the faculty of medicine of perugia, without a real laboratory, disregarded by the national scientific community and unable to move to better equipped locations. nevertheless, he proved to be a gifted teacher and popularizer of science. he published a comprehensive three-volume physics textbook that was widely used in italy and abroad. despite becoming an italian citizen in 1894, dessau's german origins led to his suspension from service during world war i. furthermore, his jewish identity made him a target of nazi-fascist antisemitism. he was dismissed from both the university of perugia and from the italian society of physics, of which he had been a member since its beginning, fortunately escaping deportation.",2024-03-10
"qcd at 50: golden anniversary, golden insights, golden opportunities","frank wilczek","high energy physics - phenomenology","the bulk of this paper centers around the tension between confinement and freedom in qcd. i discuss how it can be understood heuristically as a manifestation of self-adhesive glue and how it fits within the larger contexts of energy-time uncertainty and $\textit{real virtuality}$. i discuss the possible emergence of $\textit{treeons}$ as a tangible ingredient of (at least) pure gluon $su(3)$. i propose $\textit{flux channeling}$ as a method to address that and allied questions about triality flux numerically, and indicate how to implement it for electric and magnetic flux in material systems. that bulk is framed with broad-stroke, necessarily selective sketches of the past and possible future of strong interaction physics. at the end, i've added an expression of gratitude for my formative experience at the erice school, in 1973.",2024-03-09
"and then the hammer broke: reflections on machine ethics from feminist philosophy of science","andre ye","computers and society","vision is an important metaphor in ethical and political questions of knowledge. the feminist philosopher donna haraway points out the ``perverse'' nature of an intrusive, alienating, all-seeing vision (to which we might cry out ``stop looking at me!''), but also encourages us to embrace the embodied nature of sight and its promises for genuinely situated knowledge. current technologies of machine vision -- surveillance cameras, drones (for war or recreation), iphone cameras -- are usually construed as instances of the former rather than the latter, and for good reasons. however, although in no way attempting to diminish the real suffering these technologies have brought about in the world, i make the case for understanding technologies of computer vision as material instances of embodied seeing and situated knowing. furthermore, borrowing from iris murdoch's concept of moral vision, i suggest that these technologies direct our labor towards self-reflection in ethically significant ways. my approach draws upon paradigms in computer vision research, phenomenology, and feminist epistemology. ultimately, this essay is an argument for directing more philosophical attention from merely criticizing technologies of vision as ethically deficient towards embracing them as complex, methodologically and epistemologically important objects.",2024-03-09
"the vatican and the fallibility of science: augustine, copernicus, darwin and race","christopher m. graney","history and philosophy of physics","this paper provides an overview of work, published since the opening of the archives of the vatican congregation for the doctrine of the faith at the end of the twentieth century, regarding the vatican confronting evolution in the nineteenth century. it argues that this work, considered in light of recent studies of scientific writings by jesuit astronomers who in the seventeenth century were opposed to the ideas of copernicus, points to interesting things yet to be learned regarding the vatican's actions on heliocentrism. concern for scripture and for the fallible and consequential nature of science, together with the processes used by the vatican in these confrontations, inevitably led to messy results in these well-known ""religion and science"" confrontations. nevertheless, these confrontations suggest that what the vatican was attempting to do in confronting evolution or heliocentrism is something that is needed in science, and something that will be done in the future, probably not by the vatican, and probably in a fashion not less messy.",2024-03-08
"c.v. raman as a science communicator: a historical perspective","g.v. pavan kumar","history and philosophy of physics","c.v. raman (1888 - 1970) was a creative scientist, enthusiastic teacher and a science celebrity in india. in all these roles, he communicated science effectively. in this essay, i ask how and why did he communicate science. i take a few examples from his research writings and show his ability to explain science lucidly. by looking into his thoughts on teaching and those of his students, i explore raman, the teacher. finally, i discuss a few aspects of his methods to communicate science to the public. i emphasize his exposition and reveal a dichotomy.",2024-02-27
"promising stabs in the dark: theory virtues and pursuit-worthiness in the dark energy problem","william j. wolf, patrick m. duerr","history and philosophy of physics","the paper argues that we ought to conceive of the dark energy problem -- the question of how to account for observational data, naturally interpreted as accelerated expansion of the universe -- as a crisis of underdetermined pursuit-worthiness. not only are the various approaches to the dark energy problem evidentially underdetermined; at present, no compelling reasons single out any of them as more likely to be true than the other. more vexingly for working scientists, none of the approaches stands out as uncontroversially preferable over its rivals in terms of its rationally warranted promise, i.e. the reasons to further work on, explore and develop it. we demonstrate this claim by applying a peircean economic model of pursuit-worthiness in terms of a cognitive cost/benefit estimate -- with the instantiation of theory virtues as key indicators of cognitive gains -- to the four main dark energy proposals (the cosmological constant approach, modified gravity, quintessence, and inhomogeneous cosmologies). our analysis yields that these approaches do not admit of an unambiguous, or uncontroversial, ranking with respect to which ansatz deserves distinguished attention and research efforts. the overall methodological counsel that our analysis underwrites recommends a pragmatic double research strategy forward: to encourage and foster theory pluralism and the search for tests -- with the goal of enhancing the testability of the $\lambda$cdm model and ""testing it to destruction"".",2024-03-07
"relational quantum mechanics, quantum relativism, and the iteration of relativity","timotheus riedel","history and philosophy of physics","the idea that the dynamical properties of quantum systems are invariably relative to other systems has recently regained currency. using relational quantum mechanics (rqm) for a case study, this paper calls attention to a question that has been underappreciated in the debate about quantum relativism: the question of whether relativity iterates. are there absolute facts about the properties one system possesses relative to a specified reference, or is this again a relative matter, and so on? it is argued that rqm (in its best-known form) is committed to what i call the unrestricted iteration principle (uip), and thus to an infinite regress of relativisations. this principle plays a crucial role in ensuring the communicability and coherence of interaction outcomes across observers. it is, however, shown to be incompatible with the widespread, conservative reading of rqm in terms of relations, instead necessitating the adoption of the more unorthodox notion of perspectival facts. i conclude with some reflections on the current state of play in perspectivist versions of rqm and quantum relativism more generally, underscoring both the need for further conceptual development and the importance of the iteration principle for an accurate cost-benefit analysis of such interpretations.",2024-03-06
"lars brink: november 12, 1943 - october 29, 2022","bengt e.w. nilsson (chalmers u. tech.), björn jonson (chalmers u. tech.)","history and philosophy of physics","we give some personal reflections on the person and scientist lars brink and on some of his scientific achievements. our relations to lars are briefly described in [1] and [2], while the sources relevant for this text are summarised in [3].",2024-03-06
"astronomical lunisolar cycles and late antique chronology","d. n. starostin","history and philosophy of physics","this article advances the hypothesis that the heightened eschatological sensitivity evident among the historians writing in the 5th century and its weaker echos in the time of charlemagne were caused by the irregularities of the the lunisolar calendar and its particular realization, the easter calendar. the lunisolar calendar that christians used for the calculation of the date of the easter had a number of key periods when the cycles of the sun and the moon came in sync in relationship to the beginning of the count and thus produced an effect of the times repeating themselves or ending with the nearly precise astronomical repetition. it is shown that late antique scholars who were actively involved in the construction of the christian history's chronology were limited in their choices by the astronomical peculiarities of the earth-moon system. the total conjunctions of the astronomical solar and lunar calendars took place, some within the 1st century ce, and the next one, in 483 ce. this was also a special year because the lunar calendar lost one day. thus the 5th century was the time of heightened expectations of whether the calendar and the moon's showings will repeat those that accompanied the birth of jesus. the full supermoon (or whatever phase it was on december 25th, 1 bce) may have repeated in 410 ce (the entry of goths into rome), in 467 ce and in 476 ce (the fall of the roman empire), marking the coming of the time very similar to jesus' birth. the full moon was supposed to repeat december 25th, 800 ce and in the year 1000 ce. this may have determined the setting of the biblical calendar in a way that put the birth of christ on 5199 ce (making the year 800 ce, the year of the full supermoon or of its phase on december 25th, 1 bce) a critical turning point.",2024-03-06
"should we fear large language models? a structural analysis of the human reasoning system for elucidating llm capabilities and risks through the lens of heidegger's philosophy","jianqiiu zhang","artificial intelligence","in the rapidly evolving field of large language models (llms), there is a critical need to thoroughly analyze their capabilities and risks. central to our investigation are two novel elements. firstly, it is the innovative parallels between the statistical patterns of word relationships within llms and martin heidegger's concepts of ""ready-to-hand"" and ""present-at-hand,"" which encapsulate the utilitarian and scientific altitudes humans employ in interacting with the world. this comparison lays the groundwork for positioning llms as the digital counterpart to the faculty of verbal knowledge, shedding light on their capacity to emulate certain facets of human reasoning. secondly, a structural analysis of human reasoning, viewed through heidegger's notion of truth as ""unconcealment"" is conducted this foundational principle enables us to map out the inputs and outputs of the reasoning system and divide reasoning into four distinct categories. respective cognitive faculties are delineated, allowing us to place llms within the broader schema of human reasoning, thus clarifying their strengths and inherent limitations. our findings reveal that while llms possess the capability for direct explicative reasoning and pseudo rational reasoning, they fall short in authentic rational reasoning and have no creative reasoning capabilities, due to the current lack of many analogous ai models such as the faculty of judgement. the potential and risks of llms when they are augmented with other ai technologies are also evaluated. the results indicate that although llms have achieved proficiency in some reasoning abilities, the aspiration to match or exceed human intellectual capabilities is yet unattained. this research not only enriches our comprehension of llms but also propels forward the discourse on ai's potential and its bounds, paving the way for future explorations into ai's evolving landscape.",2024-03-05
"a very, very peculiar telescope of the 1610s","paolo del santo","history and philosophy of physics","a re-examination of a well-known iconographic source, the ""allegory of sight"" by jan brueghel the elder and peter paul rubens, reveals that one of the two telescopes depicted in the painting has a highly unusual,and until now unknown to the historians of the telescope, particularity.",2024-03-05
"a ""user experience 3.0 (ux 3.0)"" paradigm framework: user experience design for human-centered ai systems","wei xu","human-computer interaction","the human-centered artificial intelligence (hcai) design approach, the user-centered design (ucd) version in the intelligence era, has been promoted to address potential negative issues caused by ai technology; user experience design (uxd) is specifically called out to facilitate the design and development of human-centered ai systems. over the last three decades, user experience (ux) practice can be divided into three stages in terms of technology platform, user needs, design philosophy, ecosystem, scope, focus, and methodology of ux practice. ux practice is moving towards the intelligence era. still, the existing ux paradigm mainly aims at non-intelligent systems and lacks a systematic approach to address ux for designing and developing human-centered ai products and systems. the intelligence era has put forward new demands on the ux paradigm. this paper proposes a ""ux 3.0"" paradigm framework and the corresponding ux methodology for ux practice in the intelligence era. the ""ux 3.0"" paradigm framework includes four categories of emerging experiences in the intelligence era: ecosystem-based experience, innovation-enabled experience, ai-enabled experience, and human-ai interaction-based experience, each compelling us to enhance current ux practice in terms of design philosophy, scope, focus, and methodology. we believe that the ""ux 3.0"" paradigm helps enhance existing ux practice and provides methodological support for the research and applications of ux in developing human-centered ai systems. finally, this paper looks forward to future work implementing the ""ux 3.0"" paradigm.",2024-03-03
"on the time orientation of probability","andrea di biagio, carlo rovelli","history and philosophy of physics","an influential theorem by satosi wantabe convinced many that there can be no genuinely probabilistic theory with both non-trivial forward and backward transition probabilities. we show that this conclusion does not follow from the theorem. we point out the flaw in the argument, and we showcase examples of theories with well-defined backward and forward transition probabilities.",2024-03-02
"public projects with preferences and predictions","mary monroe, bo waggoner","computer science and game theory","in the public projects problem, a group of decisionmakers aggregate their preferences to choose one alternative. recent work on public projects has proposed the quadratic transfers mechanism (qtm) and shown asymptotic welfare guarantees in some cases. we begin by giving new non-asymptotic price of anarchy guarantees for the qtm. we then incorporate an alternative philosophy toward group decisionmaking, aggregation of information about which is the best alternative. we propose a public projects mechanism based on the qtm that aggregates both preferences and predictions, modeled as forecasts of the projects' welfare impacts. when the predictions come from a prediction market or wagering mechanism, we show the entire mechanism is robust to manipulation and give price of anarchy guarantees, though under strong assumptions on the mechanism's knowledge. our results focus primarily on the case of deciding between two alternatives, showing the price of anarchy tends to $1$ as natural measures of the ""size"" of the population grow large. in most cases, the mechanisms achieve a balanced budget as well.",2024-03-02
"a framework for understanding data science","michael l brodie","other statistics","the objective of this research is to provide a framework with which the data science community can understand, define, and develop data science as a field of inquiry. the framework is based on the classical reference framework (axiology, ontology, epistemology, methodology) used for 200 years to define knowledge discovery paradigms and disciplines in the humanities, sciences, algorithms, and now data science. i augmented it for automated problem-solving with (methods, technology, community). the resulting data science reference framework is used to define the data science knowledge discovery paradigm in terms of the philosophy of data science addressed in previous papers and the data science problem-solving paradigm, i.e., the data science method, and the data science problem-solving workflow, both addressed in this paper. the framework is a much called for unifying framework for data science as it contains the components required to define data science. for insights to better understand data science, this paper uses the framework to define the emerging, often enigmatic, data science problem-solving paradigm and workflow, and to compare them with their well-understood scientific counterparts, scientific problem-solving paradigm and workflow.",2024-02-14
"do zombies understand? a choose-your-own-adventure exploration of machine cognition","ariel goldstein, gabriel stanovsky","computation and language","recent advances in llms have sparked a debate on whether they understand text. in this position paper, we argue that opponents in this debate hold different definitions for understanding, and particularly differ in their view on the role of consciousness. to substantiate this claim, we propose a thought experiment involving an open-source chatbot $z$ which excels on every possible benchmark, seemingly without subjective experience. we ask whether $z$ is capable of understanding, and show that different schools of thought within seminal ai research seem to answer this question differently, uncovering their terminological disagreement. moving forward, we propose two distinct working definitions for understanding which explicitly acknowledge the question of consciousness, and draw connections with a rich literature in philosophy, psychology and neuroscience.",2024-03-01
"axe the x in xai: a plea for understandable ai","andrés páez","artificial intelligence","in a recent paper, erasmus et al. (2021) defend the idea that the ambiguity of the term ""explanation"" in explainable ai (xai) can be solved by adopting any of four different extant accounts of explanation in the philosophy of science: the deductive nomological, inductive statistical, causal mechanical, and new mechanist models. in this chapter, i show that the authors' claim that these accounts can be applied to deep neural networks as they would to any natural phenomenon is mistaken. i also provide a more general argument as to why the notion of explainability as it is currently used in the xai literature bears little resemblance to the traditional concept of scientific explanation. it would be more fruitful to use the label ""understandable ai"" to avoid the confusion that surrounds the goal and purposes of xai. in the second half of the chapter, i argue for a pragmatic conception of understanding that is better suited to play the central role attributed to explanation in xai. following kuorikoski & ylikoski (2015), the conditions of satisfaction for understanding an ml system are fleshed out in terms of an agent's success in using the system, in drawing correct inferences from it.",2024-03-01
"an improved calendar ring hole-count for the antikythera mechanism","graham woan, joseph bayley","history and philosophy of physics","we present a new analysis of the positions of holes beneath the calendar ring of the antikythera mechanism, as measured by budiselic et al. (2020). we significantly refine their estimate for the number of holes that were present in the full ring. our $68\%$-credible estimate for this number, taking account of all the data, is $355.24^{ +1.39 }_{ -1.36 }$. if holes adjacent to fractures are removed from the analysis, our estimate becomes $354.08^{ +1.47}_{-1.41}$. a ring of 360 holes is strongly disfavoured, and one of 365 holes is not plausible, given our model assumptions.",2024-02-29
"refraction, the speed of light and minimal action: from descartes to maupertuis through many more","shahen hacyan","history and philosophy of physics","in the 17th and 18th centuries, several natural philosophers studied the phenomenon of refraction and attempted to obtain the snell law from various assumptions. lacking experimental data, it was generally believed that light travels faster in a refracting medium than in air. in the present article, i review the contributions to the problem of light refraction by descartes, fermat, huygens, leibniz, newton, clairaut, and finally maupertuis who established a principle of least action based on his own approach to the problem.",2024-02-29
"the author of a quotation goethe adduced against newton","hubert kalf","history and overview","the hitherto unknown author of a citation by goethe in his history of colours is identified as j. e. montucla and the context of montucla's quotation is discussed.",2024-02-29
"exploring multilingual human value concepts in large language models: is value alignment consistent, transferable and controllable across languages?","shaoyang xu, weilong dong, zishan guo, xinwei wu, deyi xiong","computation and language","prior research in representation engineering has revealed that llms encode concepts within their representation spaces, predominantly centered around english. in this study, we extend this philosophy to a multilingual scenario, delving into multilingual human value concepts in llms. through our comprehensive exploration covering 7 types of human values, 16 languages and 3 llm series with distinct multilinguality, we empirically substantiate the existence of multilingual human values in llms. further cross-lingual analysis on these concepts discloses 3 traits arising from language resource disparities: cross-lingual inconsistency, distorted linguistic relationships, and unidirectional cross-lingual transfer between high- and low-resource languages, all in terms of human value concepts. additionally, we validate the feasibility of cross-lingual control over value alignment capabilities of llms, leveraging the dominant language as a source language. drawing from our findings on multilingual value alignment, we prudently provide suggestions on the composition of multilingual data for llms pre-training: including a limited number of dominant languages for cross-lingual alignment transfer while avoiding their excessive prevalence, and keeping a balanced distribution of non-dominant languages. we aspire that our findings would contribute to enhancing the safety and utility of multilingual ai.",2024-02-28
"the mechanical turkness: tactical media art and the critique of corporate ai","dejan grba","computers and society","the extensive industrialization of artificial intelligence (ai) since the mid-2010s has increasingly motivated artists to address its economic and sociopolitical consequences. in this chapter, i discuss interrelated art practices that thematize creative agency, crowdsourced labor, and delegated artmaking to reveal the social rootage of ai technologies and underline the productive human roles in their development. i focus on works whose poetic features indicate broader issues of contemporary ai-influenced science, technology, economy, and society. by exploring the conceptual, methodological, and ethical aspects of their effectiveness in disrupting the political regime of corporate ai, i identify several problems that affect their tactical impact and outline potential avenues for tackling the challenges and advancing the field.",2024-02-27
"spike up prime interest in science and technology through constructionist games","pavel petrovič, fedir agarshev","robotics","robotics sets have been successfully used in elementary and secondary schools in conformance with the 'learning through play' philosophy fostered by lego education, while utilizing the constructionism didactic approach. learners discover and acquire knowledge through first-hand tangible experiences, building their own representations in a constructivist learning process. usual pedagogical goals of the activities include introduction to the principles of control, mechanics, programming, and robotics [1]. they are organized as hands-on learning situations with teamwork cooperation of learners, project-based learning, sharing and presentations of the learners group experiences. arriving from this tradition, we focus on a slightly different scenarios: employing the robotics sets and the named approaches when learning physics, mathematics, art, science, and other subjects. in carefully designed projects, learners build interactive models that demonstrate concepts, principles, and phenomena, perform experiments, and modify them in elaboration phases with the aim to connect, create associations and links to the actual underlying theoretical curriculum. in this way, they are collecting practical experiences which are prerequisite to successful learning process. based on feedback from children, we continue upon two previous sets of activities that focused on physics and mathematics, this time with projects built around games. learners play various games with physical artifacts in the real-world - with the models they build. they acquire skills while playing the games, analyze them, and learn about the underlying principles. they modify the game rules, strategies, create extensions, and interact with each other in an entertaining and engaging settings. this time we have designed the activities together with the children, students of applied robotics seminar, and a student of applied informatics.",2024-02-27
"born's rule from epistemic assumptions","per östborn","quantum physics","born's rule is the recipe for calculating probabilities from quantum mechanical amplitudes. there is no generally accepted derivation of born's rule from first principles. in this paper, it is motivated from assumptions that link the ontological content of a proper physical model to the epistemic conditions of the experimental context. more precisely, it is assumed that all knowable distinctions should correspond to distinctions in a proper model. this principle of ""ontological completeness"" means, for example, that the probabilistic treatment of the double slit experiment with and without path information should differ. further, it is assumed that the model should rely only on knowable ontological elements, and that failure to fulfill this principle of ""ontological minimalism"" gives rise to wrong predictions. consequently, probabilities should be assigned only to observable experimental outcomes. also, the method to calculate such probabilities should not rely on the existence of a precise path of the observed object if this path is not knowable. a similar principle was promoted by born, even though he did not apply it to probability. another crucial assumption is that the proper rule to calculate probabilities should be generally valid. it should be applicable in all experimental contexts, regardless the setup that determines which attributes of the studied object are observed, together with the probability to observe each of the associated attribute values. there is no need to refer to the hilbert space structure of quantum mechanics in the present treatment. rather, some elements of this structure emerge from the analysis.",2024-02-26
"new prospects for a causally local formulation of quantum theory","jacob a. barandes","quantum physics","it is difficult to extract reliable criteria for causal locality from the limited ingredients found in textbook quantum theory. in the end, bell humbly warned that his eponymous theorem was based on criteria that ""should be viewed with the utmost suspicion."" remarkably, by stepping outside the wave-function paradigm, one can reformulate quantum theory in terms of old-fashioned configuration spaces together with 'unistochastic' laws. these unistochastic laws take the form of directed conditional probabilities, which turn out to provide a hospitable foundation for encoding microphysical causal relationships. this unistochastic reformulation provides quantum theory with a simpler and more transparent axiomatic foundation, plausibly resolves the measurement problem, and deflates various exotic claims about superposition, interference, and entanglement. making use of this reformulation, this paper introduces a new principle of causal locality that is intended to improve on bell's criteria, and shows directly that systems that remain at spacelike separation cannot exert causal influences on each other, according to that new principle. these results therefore lead to a general hidden-variables interpretation of quantum theory that is arguably compatible with causal locality.",2024-02-26
"whose projection postulate?","anthony sudbery","quantum physics","the projection postulate is a description of the effect on a quantum system, assumed to be in a pure state, of a measurement of an observable with a discrete spectrum, in nonrelativistic quantum mechanics. it is often called ""von neumann's projection postulate"" or ""the lüders rule"". this paper is an examination of the versions of this postulate due to dirac, von neumann and lüders. it is shown that dirac, in 1930, proposed what is now generally known as the projection postulate. von neumann, in 1932, gave a different theory which only applies in special and rather unusual cases. lüders, in 1951, rejected this theory and presented one which is the same as dirac's. treatments of observables with continuous spectra by both dirac and von neumann are criticised, and the possibility of a generalised version of the projection postulate for this case is considered. the paper concludes with a discussion of the status of the projection postulate (in its various forms) as a separate postulate (independent of the other postulates of quantum mechanics) and as a separate form of time development (in addition to the time-dependent schrödinger equation).",2024-02-23
"pre-chirp-domain index modulation for affine frequency division multiplexing","guangyao liu, tianqi mao, ruiqi liu, zhenyu xiao","information theory","affine frequency division multiplexing (afdm), tailored as a novel multicarrier technique utilizing chirp signals for high-mobility communications, exhibits marked advantages compared to traditional orthogonal frequency division multiplexing (ofdm). afdm is based on the discrete affine fourier transform (daft) with two modifiable parameters of the chirp signals, termed as the pre-chirp parameter and post-chirp parameter, respectively. these parameters can be fine-tuned to avoid overlapping channel paths with different delays or doppler shifts, leading to performance enhancement especially for doubly dispersive channel. in this paper, we propose a novel afdm structure with the pre-chirp index modulation (pim) philosophy (afdm-pim), which can embed additional information bits into the pre-chirp parameter design for both spectral and energy efficiency enhancement. specifically, we first demonstrate that the application of distinct pre-chirp parameters to various subcarriers in the afdm modulation process maintains the orthogonality among these subcarriers. then, different pre-chirp parameters are flexibly assigned to each afdm subcarrier according to the incoming bits. by such arrangement, aside from classical phase/amplitude modulation, extra binary bits can be implicitly conveyed by the indices of selected pre-chirping parameters realizations without additional energy consumption. at the receiver, both a maximum likelihood (ml) detector and a reduced-complexity ml-minimum mean square error (ml-mmse) detector are employed to recover the information bits. it has been shown via simulations that the proposed afdm-pim exhibits superior bit error rate (ber) performance compared to classical afdm, ofdm and im-aided ofdm algorithms.",2024-02-23
"the dual dynamical foundation of orthodox quantum mechanics","diana taschetto, ricardo correa da silva","history and philosophy of physics","this paper combines mathematical, philosophical, and historical analyses in a comprehensive investigation of the dynamical foundations of the formalism of orthodox quantum mechanics. the results obtained include: (i) a deduction of the canonical commutation relations (ccr) from the tenets of matrix mechanics; (ii) a discussion of the meaning of schrödinger's first derivation of the wave equation that not only improves on joas and lehner's 2009 investigation on the subject but also demonstrates that the ccr follow of necessity from schrödinger's first derivation of the wave equation, thus correcting the common misconception that the ccr were only posited by schrödinger to pursue equivalence with matrix mechanics; (iii) a discussion of the mathematical facts and requirements involved in the equivalence of matrix and wave mechanics that improves on f. a. muller's classical treatment of the subject; (iv) a proof that the equivalence of matrix and wave mechanics is necessitated by the formal requirements of a dual action functional from which both the dynamical postulates of orthodox quantum mechanics, von neumann's process 1 and process 2, follow; (v) a critical assessment, based on (iii) and (iv), of von neumann's construction of unified quantum mechanics over hilbert space. point (iv) is our main result. it brings to the open the important, but hitherto ignored, fact that orthodox quantum mechanics is no exception to the golden rule of physics that the dynamics of a physical theory must follow from the action functional. if orthodox quantum mechanics, based as it is on the assumption of the equivalence of matrix and wave mechanics, has this ""peculiar dual dynamics,"" as von neumann called it, this is so because by assuming the equivalence one has been assuming a peculiar dual action.",2024-02-23
"the spectrum of he$^+$ as a proving ground for bohr's model of the atom: a legacy of williamina fleming's astrophysical discovery","maria mceachern, bretislav friedrich","atomic physics","in 1896, edward charles pickering (1846-1919), director of the harvard college observatory (hco), reported in a trio of publications the observation of ""peculiar spectra"" of the southern star $\zeta$ puppis, which he attributed to an ""element not yet found in other stars or on earth."" supported by laboratory spectra obtained by alfred fowler (1868-1940), niels bohr (1885-1962) showed in 1913 that this ""element"" was in fact ionized helium, he$^+$. its spectrum has become known as the pickering series, even though pickering credited williamina fleming (1857-1911) for the discovery. fleming was one of hco's ""computers"" and the future curator of the astronomical photographic glass plate collection. the series of spectral lines associated with pickering's name played a unique role on the path to quantum mechanics by serving as a proving ground for bohr's model of the atom. our examination of the discovery of the pickering series relied on the records held at the center for astrophysics $\vert$ harvard \& smithsonian (the successor institution to hco), especially the notebooks and diaries of williamina fleming and others as well as on the center's glass plate collection. glimpses of the ""peculiar sociology"" of a research institution, half of whose staff were women employed on grossly unequal terms with men, are given in the course of the narrative.",2024-02-22
"on gibbs equilibrium and hillert nonequilibrium thermodynamics","zi-kui liu","statistical mechanics","during his time at royal institute of technology (kungliga tekniska hogskolan, kth) in sweden, the present author learned nonequilibrium thermodynamics from mats hillert. the key concept is the separation of internal and external variables of a system. in equilibrium thermodynamics derived by gibbs, the internal variables are not independent and can be fully evaluated from given external variables. while irreversible thermodynamics led by onsager focuses on internal variables though often mixed with external variables. hillert integrated them together by first emphasizing their differences and then examining their connections. his philosophy was reflected by the title of his book ""phase equilibria, phase diagrams and phase transformations"" that puts equilibrium, nonequilibrium, and internal processes on equal footing. in the present paper honoring hillert, the present author reflects his experiences with hillert in last 35 years and expresses his gratitude for all the wisdom and support from him in terms of ""hillert nonequilibrium thermodynamics"" and discusses some recent topics that the present author has been working on.",2024-02-22
"betting on what is neither verifiable nor falsifiable","abhimanyu pallavi sudhir, long tran-thanh","computer science and game theory","prediction markets are useful for estimating probabilities of claims whose truth will be revealed at some fixed time -- this includes questions about the values of real-world events (i.e. statistical uncertainty), and questions about the values of primitive recursive functions (i.e. logical or algorithmic uncertainty). however, they cannot be directly applied to questions without a fixed resolution criterion, and real-world applications of prediction markets to such questions often amount to predicting not whether a sentence is true, but whether it will be proven. such questions could be represented by countable unions or intersections of more basic events, or as first-order-logic sentences on the arithmetical hierarchy (or even beyond fol, as hyperarithmetical sentences). in this paper, we propose an approach to betting on such events via options, or equivalently as bets on the outcome of a ""verification-falsification game"". our work thus acts as an alternative to the existing framework of garrabrant induction for logical uncertainty, and relates to the stance known as constructivism in the philosophy of mathematics; furthermore it has broader implications for philosophy and mathematical logic.",2024-01-29
"the dynamics of neural codes in biological and artificial neural networks","guillermo b. morales","neurons and cognition","advancing our knowledge of how the brain processes information remains a key challenge in neuroscience. this thesis combines three different approaches to the study of the dynamics of neural networks and their encoding representations: a computational approach, that builds upon basic biological features of neurons and their networks to construct effective models that can simulate their structure and dynamics; a machine-learning approach, which draws a parallel with the functional capabilities of brain networks, allowing us to infer the dynamical and encoding properties required to solve certain input-processing tasks; and a final, theoretical treatment, which will take us into the fascinating hypothesis of the ""critical"" brain as the mathematical foundation that can explain the emergent collective properties arising from the interactions of millions of neurons. hand in hand with physics, we venture into the realm of neuroscience to explain the existence of quasi-universal scaling properties across brain regions, setting out to quantify the distance of their dynamics from a critical point. next, we move into the grounds of artificial intelligence, where the very same theory of critical phenomena will prove very useful for explaining the effects of biologically-inspired plasticity rules in the forecasting ability of reservoir computers. halfway into our journey, we explore the concept of neural representations of external stimuli, unveiling a surprising link between the dynamical regime of neural networks and the optimal topological properties of such representation manifolds. the thesis ends with the singular problem of representational drift in the process of odor encoding carried out by the olfactory cortex, uncovering the potential synaptic plasticity mechanisms that could explain this recently observed phenomenon.",2024-02-20
"making sense of gravitational thermodynamics","lorenzo lorenzetti","history and philosophy of physics","the use of statistical methods to model gravitational systems is crucial to physics practice, but the extent to which thermodynamics and statistical mechanics genuinely apply to these systems is a contentious issue. this paper provides new conceptual foundations for gravitational thermodynamics by reconsidering the nature of key concepts like equilibrium and advancing a novel way of understanding thermodynamics. the challenges arise from the peculiar characteristics of the gravitational potential, leading to non-extensive energy and entropy, negative heat capacity, and a lack of standard equilibrium. hence it has been claimed that only non-equilibrium statistical mechanics is warranted in this domain, whereas thermodynamics is inapplicable. we argue instead that equilibrium statistical mechanics applies to self-gravitating systems at the relevant scale, as they display equilibrium in the form of metastable quasi-equilibrium states. we then develop a minimal framework for thermodynamics that can be applied to these systems and beyond. thermodynamics applies in the sense that we can devise macroscopic descriptions and explanations of the behaviour of these systems in terms of coarse-grained quantities within equilibrium statistical mechanics.",2024-02-18
"causal equal protection as algorithmic fairness","marcello di bello, nicolò cangiotti, michele loi","computers and society","over the last ten years the literature in computer science and philosophy has formulated different criteria of algorithmic fairness. one of the most discussed, classification parity, requires that the erroneous classifications of a predictive algorithm occur with equal frequency for groups picked out by protected characteristics. despite its intuitive appeal, classification parity has come under attack. multiple scenarios can be imagined in which - intuitively - a predictive algorithm does not treat any individual unfairly, and yet classification parity is violated. to make progress, we turn to a related principle, equal protection, originally developed in the context of criminal justice. key to equal protection is equalizing the risks of erroneous classifications (in a sense to be specified) as opposed to equalizing the rates of erroneous classifications. we show that equal protection avoids many of the counterexamples to classification parity, but also fails to model our moral intuitions in a number of common scenarios, for example, when the predictor is causally downstream relative to the protected characteristic. to address these difficulties, we defend a novel principle, causal equal protection, that models the fair allocation of the risks of erroneous classification through the lenses of causality.",2024-02-19
"learning to edit: aligning llms with knowledge editing","yuxin jiang, yufei wang, chuhan wu, wanjun zhong, xingshan zeng, jiahui gao, liangyou li, xin jiang, lifeng shang, ruiming tang, qun liu, wei wang","computation and language","knowledge editing techniques, aiming to efficiently modify a minor proportion of knowledge in large language models (llms) without negatively impacting performance across other inputs, have garnered widespread attention. however, existing methods predominantly rely on memorizing the updated knowledge, impeding llms from effectively combining the new knowledge with their inherent knowledge when answering questions. to this end, we propose a learning to edit (lte) framework, focusing on teaching llms to apply updated knowledge into input questions, inspired by the philosophy of ""teach a man to fish."" lte features a two-phase process: (i) the alignment phase, which fine-tunes llms on a meticulously curated parallel dataset to make reliable, in-scope edits while preserving out-of-scope information and linguistic proficiency; and (ii) the inference phase, which employs a retrieval-based mechanism for real-time and mass knowledge editing. by comparing our approach with seven advanced baselines across four popular knowledge editing benchmarks and two llm architectures, we demonstrate lte's superiority in knowledge editing performance, robustness in both batch and sequential editing, minimal interference on general tasks, and rapid editing speeds. the data and code are available at this https url.",2024-02-19
"c. v. vishveshwara (vishu) on the black hole trek","naresh dadhich, k rajesh nayak","general relativity and quantum cosmology","with his seminal and pioneering work on the stability of the schwarzschild black hole and its interaction with gravitational radiation, vishu had opened a new window on black hole astrophysics. one of the interesting results that soon followed was that ""a black hole has no hair"", it is entirely specified by the three parameters, mass, spin and charge, and nothing more. the discovery of gravitational waves in 2016 produced by merger of two black holes, and observed by the ligo-virgo collaboration, carried the definitive signature of quasi-normal modes, the phenomenon of black hole ringdown, exactly what vishu had predicted in his 1970 nature paper~(see isaacson's commentary) 46 years ago. this was the crowning glory.",2024-02-18
"a review of 70 years with astrometry","erik høg","instrumentation and methods for astrophysics","in 1953 i heard of an experiment in 1925 by bengt strömgren where he observed transit times with the meridian circle at the copenhagen university observatory measuring the current in a photocell behind slits when a star was crossing. in 1954 just 22 years old i was given the task as a student to make first test observations with a new meridian circle of the observatory. i became fascinated by the instrument and by the importance of astrometry for astronomy. work at four meridian circles, two in denmark, one in hamburg, one in lund, and pierre lacroute's vision of space astrometry in france had by 1973 created the foundation for development of the hipparcos satellite, and gaia followed. in 2013 i proposed a successor satellite which has gained momentum especially thanks to the efforts of david hobbs and it has a good chance to be launched by esa about 2045. but 70 years ago, optical astrometry was considered a dying branch of astronomy, unattractive compared with astrophysics. the following growth built on the still active interest in astrometry in europe in those years and it was supported by esa, the european space agency. this review is only about astrometry where i was personally involved.",2024-02-16
"""understanding ai"": semantic grounding in large language models","holger lyre","computation and language","do llms understand the meaning of the texts they generate? do they possess a semantic grounding? and how could we understand whether and what they understand? i start the paper with the observation that we have recently witnessed a generative turn in ai, since generative models, including llms, are key for self-supervised learning. to assess the question of semantic grounding, i distinguish and discuss five methodological ways. the most promising way is to apply core assumptions of theories of meaning in philosophy of mind and language to llms. grounding proves to be a gradual affair with a three-dimensional distinction between functional, social and causal grounding. llms show basic evidence in all three dimensions. a strong argument is that llms develop world models. hence, llms are neither stochastic parrots nor semantic zombies, but already understand the language they generate, at least in an elementary sense.",2024-02-16
"the evenki accounts of the 1908 tunguska event collected in 1920s-1930s","andrei ol'khovatov","history and philosophy of physics","this paper is a continuation of a series of works, devoted to various aspects of the 1908 tunguska event. it is devoted to the evenki accounts of the 1908 tunguska event collected in 1920s - 1930s. it is important to research accounts of evenki who were rather close to the epicenter. the evenki accounts are important also, because evenki are natural hunters and pathfinders - their lives depend on their memory and vision. most of the reviewed in this work accounts were collected at the evenki conference, when telling a lie was considered to be a serious misconduct. these evenki accounts are compared with other tunguska accounts. also weather conditions associated with the tunguska event are considered. some manifestations of the tunguska event are discussed.",2023-12-18
"identification is pointless: quantum reference frames, localisation of events, and the quantum hole argument","viktoria kabel, anne-catherine de la hamette, luca apadula, carlo cepollaro, henrique gomes, jeremy butterfield, časlav brukner","quantum physics","the study of quantum reference frames (qrfs) is motivated by the idea of taking into account the quantum properties of the reference frames that we use, explicitly or implicitly, in our description of physical systems. like a classical reference frame, a qrf can be used to define physical quantities such as time, position, momentum, and spin relationally. unlike its classical analogue, it relativises the notions of superposition and entanglement. here, we provide a novel explanation for the frame-dependence of superposition and entanglement by tracing it back to the question of how configurations or locations are identified across different branches in superposition. we show that, in the presence of symmetries, whether a system is in 'the same' or 'different' configurations across the branches depends on the choice of qrf. thus, sameness and difference-and, as a result, superposition and entanglement-lose their absolute meaning. we apply these ideas to semi-classical spacetimes in superposition and use coincidences of four scalar fields to construct a comparison map between the spacetime points in the different branches. this allows us to determine whether a given event is located at 'the same' or 'different' points in the superposed spacetimes. since this feature depends on the choice of qrf, we argue that the localisation of an event should not be seen as an inherent property. this alleviates previously voiced concerns that qrf changes could have empirical consequences for interference experiments, such as the bmv proposal. moreover, it implies that the number of events is equal in both the flat and the curved spacetime implementations of indefinite causal order. we conclude with the 'quantum hole argument' as a generalisation of einstein's hole argument, arguing that not just spacetime points but also their identification across a superposition lose their absolute physical meaning.",2024-02-15
"text-based product matching -- semi-supervised clustering approach","alicja martinek, szymon łukasik, amir h. gandomi","databases","matching identical products present in multiple product feeds constitutes a crucial element of many tasks of e-commerce, such as comparing product offerings, dynamic price optimization, and selecting the assortment personalized for the client. it corresponds to the well-known machine learning task of entity matching, with its own specificity, like omnipresent unstructured data or inaccurate and inconsistent product descriptions. this paper aims to present a new philosophy to product matching utilizing a semi-supervised clustering approach. we study the properties of this method by experimenting with the idec algorithm on the real-world dataset using predominantly textual features and fuzzy string matching, with more standard approaches as a point of reference. encouraging results show that unsupervised matching, enriched with a small annotated sample of product links, could be a possible alternative to the dominant supervised strategy, requiring extensive manual data labeling.",2024-02-01
"history of lattice field theory from a statistical perspective","wolfgang bietenholz","high energy physics - lattice","researchers working in lattice field theory constitute an established community since the early 1990s, and around the same time the online open-access e-print repository arxiv was created. the fact that this field has a specific arxiv section, hep-lat, which is comprehensively used, provides a unique opportunity for a statistical study of its evolution over the last three decades. we present data for the number of entries, $e$, published papers, $p$, and citations, $c$, in total and separated by nations. we compare them to six other arxiv sections (hep-ph, hep-th, gr-qc, nucl-th, quant-ph, cond-mat) and to two socio-economic indices of the nations involved: the gross domestic product (gdp) and the education index (ei). we present rankings, which are based either on the hirsch index h, or on the linear combination $\sigma = e + p + 0.05 c$. we consider both extensive and intensive national statistics, i.e. absolute and relative to the population or to the gdp.",2024-02-15
"physics, scientific investigation and society in argentina, 1920-1930","alejandro gangui, eduardo l. ortiz","history and philosophy of physics","we analyse the scientific research carried out at the institute of physics of the national university of la plata in the first half of the 20th century, and the cultural and social context in which they were immersed. we focus especially on the activities carried out by the argentine physicist ramon g. loyarte, who was an emblematic personality in the scientific, educational, cultural and political world of argentina in those years. we discuss his most important works in experimental physics and quantum mechanics, his activities in the management and promotion of science and the international impact of his scientific proposals, as well as the origin of the controversies unleashed by his most daring ideas. for the latter topics we employ a novel tool: we examine the comments on his work published in prestigious international scientific review journals, which help to understand loyarte's findings in a more comprehensive and contemporary way.",2024-02-14
"a note on the origin of inertia","a. schlatter, r. e. kastner","general relativity and quantum cosmology","the question of where the inertial properties of matter come from has been open for a long time. isaac newton considered inertia an intrinsic property of matter. ernst mach held a different view whereby the inertia of a body comes from its interaction with the rest of the universe. this idea is known today as mach's principle. we discuss mach's principle based on transactional gravity, the recently developed completion of the entropic gravity program by the physics of quantum events induced by transactions. a consequence of the analysis is a fundamental relation between the gravitational constant g and the total mass in the causal universe, derived by means of entropic principles.",2024-02-14
"same-diff? conceptual similarities between gauge transformations and diffeomorphisms. part iii: representational conventions and relationism","henrique gomes","history and philosophy of physics","the following questions are germane to our understanding of gauge-(in)variant quantities and physical possibility: in which ways are gauge transformations and spacetime diffeomorphisms similar, and in which are they different? sophistication is the most popular attitude towards some of these questions: roughly, it takes models related by these symmetries to represent the same physical possibility. in the previous paper in this series, i discussed obstacles to sophistication and then showed how these obstacles are overcome by theories that fulfill three desiderata (i-iii). but this resolution still leaves open two main worries about sophistication: (a) it allows the individuation of structure-tokens to remain intractably prolix and thus of limited use, which is why practising physicists frequently invoke 'relational, symmetry-invariant observables'; and (b) it leaves us with no formal framework for expressing counterfactual statements about the world. here i will show that a third desideratum, (iii), answers these worries. the new desideratum requires a `relational' understanding \emph{of coordinates} (or frames, etc).",2024-02-14
"awareness in robotics: an early perspective from the viewpoint of the eic pathfinder challenge ""awareness inside''","cosimo della santina, carlos hernandez corbato, burak sisman, luis a. leiva, ioannis arapakis, michalis vakalellis, jean vanderdonckt, luis fernando d'haro, guido manzi, cristina becchio, aïda elamrani, mohsen alirezaei, ginevra castellano, dimos v. dimarogonas, arabinda ghosh, sofie haesaert, sadegh soudjani, sybert stroeve, paul verschure, davide bacciu, ophelia deroy, bahador bahrami, claudio gallicchio, sabine hauert, ricardo sanz, pablo lanillos, giovanni iacca, stephan sigg, manel gasulla, luc steels, carles sierra","robotics","consciousness has been historically a heavily debated topic in engineering, science, and philosophy. on the contrary, awareness had less success in raising the interest of scholars in the past. however, things are changing as more and more researchers are getting interested in answering questions concerning what awareness is and how it can be artificially generated. the landscape is rapidly evolving, with multiple voices and interpretations of the concept being conceived and techniques being developed. the goal of this paper is to summarize and discuss the ones among these voices connected with projects funded by the eic pathfinder challenge called ``awareness inside'', a nonrecurring call for proposals within horizon europe designed specifically for fostering research on natural and synthetic awareness. in this perspective, we dedicate special attention to challenges and promises of applying synthetic awareness in robotics, as the development of mature techniques in this new field is expected to have a special impact on generating more capable and trustworthy embodied systems.",2024-02-14
"thinking twice inside the box: is wigner's friend really quantum?","caroline l. jones, markus p. mueller","quantum physics","there has been a surge of recent interest in the wigner's friend paradox, sparking several novel thought experiments and no-go theorems. the main narrative has been that wigner's friend highlights a counterintuitive feature that is unique to quantum theory, and which is closely related to the quantum measurement problem. here, we challenge this view. we argue that the gist of the wigner's friend paradox can be reproduced without assuming quantum physics, and that it underlies a much broader class of enigmas in the foundations of physics and philosophy. to show this, we first consider several recently proposed extended wigner's friend scenarios, and demonstrate that their implications for the absoluteness of observations can be reproduced by classical thought experiments that involve the duplication of agents. crucially, some of these classical scenarios are technologically much easier to implement than their quantum counterparts. then, we argue that the essential structural ingredient of all these scenarios is a feature that we call ""restriction a"": essentially, that a physical theory cannot give us a probabilistic description of the observations of all agents. finally, we argue that this difficulty is at the core of other puzzles in the foundations of physics and philosophy, and demonstrate this explicitly for cosmology's boltzmann brain problem. our analysis suggests that wigner's friend should be studied in a larger context, addressing a frontier of human knowledge that exceeds the boundaries of quantum physics: to obtain reliable predictions for experiments in which these predictions can be privately but not intersubjectively verified.",2024-02-13
"what is the q of a blackbody? a small contribution to gustav robert kirchhoff's bicentennial","arthur ballato, john ballato","quantum physics","the blackbody spectrum ""half-power points"" are used to assign effective q ""quality factor"" values that are found to be less than unity whether frequency or wavelength scaling is used. a comparison with values for coherent oscillators is made. this exercise blends two of kirchhoff's interests, and is instructive in its own right, as it bridges the often mutually exclusive engineering and scientific disciplines.",2024-02-09
"yuri lvovich klimontovich, his theory of fluctuations and its impact on the kinetic theory","michael bonitz, anatoly zagorodny","history and philosophy of physics","yuri l'vovich klimontovich (28.09.1924--26.10.2002) was an outstanding theoretical physicist who made major contributions to kinetic theory. on the occasion of his 100th birthday we recall his main scientific achievements.",2024-02-07
"the reasons that agents act: intention and instrumental goals","francis rhys ward, matt macdermott, francesco belardinelli, francesca toni, tom everitt","artificial intelligence","intention is an important and challenging concept in ai. it is important because it underlies many other concepts we care about, such as agency, manipulation, legal responsibility, and blame. however, ascribing intent to ai systems is contentious, and there is no universally accepted theory of intention applicable to ai agents. we operationalise the intention with which an agent acts, relating to the reasons it chooses its decision. we introduce a formal definition of intention in structural causal influence models, grounded in the philosophy literature on intent and applicable to real-world machine learning systems. through a number of examples and results, we show that our definition captures the intuitive notion of intent and satisfies desiderata set-out by past work. in addition, we show how our definition relates to past concepts, including actual causality, and the notion of instrumental goals, which is a core idea in the literature on safe ai agents. finally, we demonstrate how our definition can be used to infer the intentions of reinforcement learning agents and language models from their behaviour.",2024-02-11
"bgg resolutions, koszulity, and stratifications, part i: the nilbrauer algebra","fan zhou","representation theory","in this paper we homologically construct a (functorial) bgg resolution of the finite-dimensional simple module of the nilbrauer algebra by using infinity-categorical methods following the reconstruction-from-stratification philosophy, e.g. appearing in ayala-mazel-gee-rozenblyum. to do so, we prove a fact of independent interest, that half of the nilbrauer algebra is koszul. this bgg resolution categorifies a character formula of brundan-wang-webster. more generally, we have a (functorial) ``bgg spectral sequence'' which converges to any desired module; this spectral sequence is secretly a resolution when the desired module is finite-dimensional. this spectral sequence also categorifies the character formulae of brundan-wang-webster for any (possibly infinite-dimensional) simple module. we expect the methods used here for producing bgg resolutions to be applicable to other (graded) triangular-based algebras also, especially diagrammatic ones.",2024-02-10
"everettian branching in the world and of the world","nadia blackshaw, nick huggett, james ladyman","quantum physics","this paper investigates the formation and propagation of wavefunction `branches' through the process of entanglement with the environment. while this process is a consequence of unitary dynamics, and hence significant to many if not all approaches to quantum theory, it plays a central role in many recent articulations of the everett or `many worlds' interpretation. a highly idealized model of a locally interacting system and environment is described, and investigated in several situations in which branching occurs, including those involving bell inequality violating correlations; we illustrate how any non-locality is compatible with the locality of the dynamics. although branching is particularly important for many worlds quantum theory, we take a neutral stance here, simply tracing out the consequences of a unitary dynamics. the overall goals are to provide a simple concrete realization of the quantum physics of branch formation, and especially to emphasise the compatibility of branching with relativity; the paper is intended to illuminate matters both for foundational work, and for the application of quantum theory to non-isolated systems.",2024-02-10
"a survey of a random matrix model for a family of cusp forms","owen barrett, zoë x. batterman, aditya jambhale, steven j. miller, akash l. narayanan, kishan sharma, chris yao","number theory","the katz-sarnak philosophy states that statistics of zeros of $l$-function families near the central point as the conductors tend to infinity agree with those of eigenvalues of random matrix ensembles as the matrix size tends to infinity. while numerous results support this conjecture, s. j. miller observed that for finite conductors, very different behavior can occur for zeros near the central point in elliptic curve families. this led to the excised model of dueñez, huynh, keating, miller, and snaith, whose predictions for quadratic twists of a given elliptic curve are beautifully fit by the data. the key ingredients are relating the discretization of central values of the $l$-functions to excising matrices based on the value of the characteristic polynomials at 1 and using lower order terms (in statistics such as the one-level density and pair-correlation) to adjust the matrix size. we discuss recent successes by the authors in extending this model to a family of quadratic twists of finite conductor of a given holomorphic cuspidal newform of level an odd prime level. in particular, we predict very little repulsion for forms with weight greater than 2.",2024-01-29
"subalgebra and khovanskii bases equivalence","colin alstad, michael burr, oliver clarke, timothy duff","algebraic geometry","the main results of this paper establish a partial correspondence between two previously-studied analogues of groebner bases in the setting of algebras: namely, subalgebra (aka sagbi) bases for quotients of polynomial rings and khovanskii bases for valued algebras. we aim to bridge the gap between the concrete, computational aspects of the former and the more abstract theory of the latter. our philosophy is that most interesting examples of khovanskii bases can also be realized as subalgebra bases and vice-versa. we also discuss the computation of newton-okounkov bodies, illustrating how interpreting khovanskii bases as subalgebra bases makes them more amenable to the existing computer algebra tools.",2024-02-08
"berta karlik -- the grande dame of the vienna radium institute","brigitte strohmaier","history and philosophy of physics","berta karlik was an austrian physicist who was not only among the early radioactivity researchers and nuclear physicists in vienna, but also pioneered a woman's academic career in austria. she was the first woman at the university of vienna to acquire the venia legendi in physics, and the first full professor at a philosophical faculty in austria. for almost thirty years she was the head of the institute for radium research of the austrian academy of sciences.",2024-02-08
"quantum ontology de-naturalized: what we can't learn from quantum mechanics","raoni arroyo, jonas r. becker arenhart","history and philosophy of physics","philosophers of science commonly connect ontology and science, stating that these disciplines maintain a two-way relationship: on the one hand, we can extract ontology from scientific theories; on the other hand, ontology provides the realistic content of our scientific theories. in this article, we will critically examine the process of naturalizing ontology, i.e., confining the work of ontologists merely to the task of pointing out which entities certain theories commit themselves to. we will use non-relativistic quantum mechanics as a case study. we begin by distinguishing two roles for ontology: the first would be characterized by cataloging existing entities according to quantum mechanics; the second would be characterized by establishing more general ontological categories in which existing entities must be classified. we argue that only the first step is available for a naturalistic approach; the second step not being open for determination or anchoring in science. finally, we also argue that metaphysics is still a step beyond ontology, not contained in either of the two tasks of ontology, being thus even farther from science.",2024-02-08
"research on the evolution of domestic multi-functional meter technology","zhen zhang","instrumentation and detectors","the technical evolution of domestic multi-functional electricity meter is deeply discussed. with the rapid development of the domestic power market and the continuous innovation of technology, the domestic multi-functional electricity meters have experienced the transformation from simple billing to complex multi-functional, from a single application to a wide range of fields. this transformation has not only driven the rapid development of electricity meter technology, but also met the increasing power demand and management requirements. this paper expounds the concept of multi-function meter, the working principle and algorithm of digital multiplier, the initiation and evolution of multi-function electricity meter standard, and the initiation and evolution of domestic multi-function electricity meter products. although the domestic independent production of multi-functional meter has made great achievements in performance, but in the reliability and key process technology still need to be improved. in addition, the development of communication technology also provides a new opportunity for the progress of electricity meter technology. the application of the new technology provides a more convenient and efficient way for the data transmission and remote management of electricity meters. domestic multi-functional electricity meters have made remarkable achievements in technology evolution and application and expansion, but they still face some challenges and opportunities. in the future, with the continuous development of the power market and the promotion of smart grid construction, domestic multi-functional electricity meters need to continue to strengthen technological innovation and product research and development, improve the reliability and competitiveness of products, in order to meet higher application needs and market requirements.",2024-02-08
"$λ$-eclipse: multi-concept personalized text-to-image diffusion models by leveraging clip latent space","maitreya patel, sangmin jung, chitta baral, yezhou yang","computer vision and pattern recognition","despite the recent advances in personalized text-to-image (p-t2i) generative models, subject-driven t2i remains challenging. the primary bottlenecks include 1) intensive training resource requirements, 2) hyper-parameter sensitivity leading to inconsistent outputs, and 3) balancing the intricacies of novel visual concept and composition alignment. we start by re-iterating the core philosophy of t2i diffusion models to address the above limitations. predominantly, contemporary subject-driven t2i approaches hinge on latent diffusion models (ldms), which facilitate t2i mapping through cross-attention layers. while ldms offer distinct advantages, p-t2i methods' reliance on the latent space of these diffusion models significantly escalates resource demands, leading to inconsistent results and necessitating numerous iterations for a single desired image. recently, eclipse has demonstrated a more resource-efficient pathway for training unclip-based t2i models, circumventing the need for diffusion text-to-image priors. building on this, we introduce $\lambda$-eclipse. our method illustrates that effective p-t2i does not necessarily depend on the latent space of diffusion models. $\lambda$-eclipse achieves single, multi-subject, and edge-guided t2i personalization with just 34m parameters and is trained on a mere 74 gpu hours using 1.6m image-text interleaved data. through extensive experiments, we also establish that $\lambda$-eclipse surpasses existing baselines in composition alignment while preserving concept alignment performance, even with significantly lower resource utilization.",2024-02-07
"towards a process-based approach to consciousness and collapse in quantum mechanics","raoni arroyo, lauro de matos nunes filho, frederik moreira dos santos","history and philosophy of physics","according to a particular interpretation of quantum mechanics, the causal role of human consciousness in the measuring process is called upon to solve a foundational problem called the ""measurement problem"". traditionally, this interpretation is tied up with the metaphysics of substance dualism. as such, this interpretation of quantum mechanics inherits the dualist's mind-body problem. our working hypothesis is that a process-based approach to the consciousness causes collapse interpretation (ccci) -- leaning on whitehead's solution to the mind-body problem -- offers a better metaphysical understanding of consciousness and its role in interpreting quantum mechanics. this article is the kickoff for such a research program in the metaphysics of science.",2024-02-06
"does $e=mc^2$ require relativity?","tony rothman","history and philosophy of physics","it is universally believed that with his 1905 paper ``does the inertia of a body depend on its energy content?"" einstein first demonstrated the equivalence of mass and energy by making use of his new special theory of relativity. in the final step of that paper, however, einstein equates the kinetic energy of a body to its newtonian value, indicating that his result is at best a low-velocity approximation. today, several characters debate whether a mid-nineteenth century physicist, employing only galilean and pre-maxwellian physics could plausibly arrive at the celebrated result. in other words, is einsteinian relativity necessary to derive ${\mathcal e}=mc^2$?",2024-02-06
"a call for embodied ai","giuseppe paolo, jonas gonzalez-billandon, balázs kégl","artificial intelligence","we propose embodied ai as the next fundamental step in the pursuit of artificial general intelligence, juxtaposing it against current ai advancements, particularly large language models. we traverse the evolution of the embodiment concept across diverse fields - philosophy, psychology, neuroscience, and robotics - to highlight how eai distinguishes itself from the classical paradigm of static learning. by broadening the scope of embodied ai, we introduce a theoretical framework based on cognitive architectures, emphasizing perception, action, memory, and learning as essential components of an embodied agent. this framework is aligned with friston's active inference principle, offering a comprehensive approach to eai development. despite the progress made in the field of ai, substantial challenges, such as the formulation of a novel ai learning theory and the innovation of advanced hardware, persist. our discussion lays down a foundational guideline for future embodied ai research. highlighting the importance of creating embodied ai agents capable of seamless communication, collaboration, and coexistence with humans and other intelligent entities within real-world environments, we aim to steer the ai community towards addressing the multifaceted challenges and seizing the opportunities that lie ahead in the quest for agi.",2024-02-06
"large language models as moocs graders","shahriar golchin, nikhil garuda, christopher impey, matthew wenger","computation and language","massive open online courses (moocs) unlock the doors to free education for anyone around the globe with access to a computer and the internet. despite this democratization of learning, the massive enrollment in these courses means it is almost impossible for one instructor to assess every student's writing assignment. as a result, peer grading, often guided by a straightforward rubric, is the method of choice. while convenient, peer grading often falls short in terms of reliability and validity. in this study, using 18 distinct settings, we explore the feasibility of leveraging large language models (llms) to replace peer grading in moocs. specifically, we focus on two state-of-the-art llms: gpt-4 and gpt-3.5, across three distinct courses: introductory astronomy, astrobiology, and the history and philosophy of astronomy. to instruct llms, we use three different prompts based on a variant of the zero-shot chain-of-thought (zero-shot-cot) prompting technique: zero-shot-cot combined with instructor-provided correct answers; zero-shot-cot in conjunction with both instructor-formulated answers and rubrics; and zero-shot-cot with instructor-offered correct answers and llm-generated rubrics. our results show that zero-shot-cot, when integrated with instructor-provided answers and rubrics, produces grades that are more aligned with those assigned by instructors compared to peer grading. however, the history and philosophy of astronomy course proves to be more challenging in terms of grading as opposed to other courses. finally, our study reveals a promising direction for automating grading systems for moocs, especially in subjects with well-defined rubrics.",2024-02-06
"quantum panprotopsychism and the combination problem","rodolfo gambini, jorge pullin","history and philosophy of physics","we will argue that a phenomenological analysis of consciousness, similar to that of husserl, shows that the effects of phenomenal qualities shape our perception of the world. it also shows the way the physical and mathematical sciences operate, allowing us to accurately describe the observed regularities in terms of communicable mathematical laws. the latter say nothing about the intrinsic features of things. they only refer to the observed regularities in their behaviors, providing rigorous descriptions of how the universe works, to which any viable ontology must conform. classical mechanistic determinism limits everything that can occur to what happens in an instant and leaves no room for novelty or any intrinsic aspect that is not epiphenomenal. the situation changes with quantum probabilistic determinism if one takes seriously the ontology that arises from its axioms of objects, systems in certain states, and the events they produce in other objects. as bertrand russell pointed out almost a century ago, an ontology of events, with an internal phenomenal aspect, now known as panprotopsychism, is better suited to explaining the phenomenal aspects of consciousness. the central observation of this paper is that many objections to panpsychism and panprotopsychism, which are usually called the combination problem, arise from implicit hypotheses based on classical physics about supervenience. these are inappropriate at the quantum level, where an exponential number of emergent properties and states arise. the analysis imposes conditions on the possible implementations of quantum cognition mechanisms in the brain.",2024-02-04
"what do we teach to engineering students: embedded ethics, morality, and politics","avigail ferdman, emanuele ratti","computers and society","in the past few years, calls for integrating ethics modules in engineering curricula have multiplied. despite this positive trend, a number of issues with these embedded programs remains. first, learning goals are underspecified. a second limitation is the conflation of different dimensions under the same banner, in particular confusion between ethics curricula geared towards addressing the ethics of individual conduct and curricula geared towards addressing ethics at the societal level. in this article, we propose a tripartite framework to overcome these difficulties. our framework analytically decomposes an ethics module into three dimensions. first, there is the ethical dimension, which pertains to the learning goals. second, there is the moral dimension, which addresses the moral relevance of engineers conduct. finally, there is the political dimension, which scales up issues of moral relevance at the civic level. all in all, our framework has two advantages. first, it provides analytic clarity, i.e. it enables course instructors to locate ethical dilemmas in either the moral or political realm and to make use of the tools and resources from moral and political philosophy. second, it depicts a comprehensive ethical training, which enables students to both reason about moral issues in the abstract, and to socially contextualize potential solutions.",2024-02-05
"large language model adaptation for networking","duo wu, xianda wang, yaqi qiao, zhi wang, junchen jiang, shuguang cui, fangxin wang","networking and internet architecture","many networking tasks now employ deep learning (dl) to solve complex prediction and system optimization problems. however, current design philosophy of dl-based algorithms entails intensive engineering overhead due to the manual design of deep neural networks (dnns) for different networking tasks. besides, dnns tend to achieve poor generalization performance on unseen data distributions/environments. motivated by the recent success of large language models (llms), for the first time, this work studies the llm adaptation for networking to explore a more sustainable design philosophy. with the massive pre-trained knowledge and powerful inference ability, llm can serve as the foundation model, and is expected to achieve ""one model for all"" with even better performance and stronger generalization for various tasks. in this paper, we present netllm, the first llm adaptation framework that efficiently adapts llms to solve networking problems. netllm addresses many practical challenges in llm adaptation, from how to process task-specific information with llms, to how to improve the efficiency of answer generation and acquiring domain knowledge for networking. across three networking-related use cases - viewport prediction (vp), adaptive bitrate streaming (abr) and cluster job scheduling (cjs), we showcase the effectiveness of netllm in llm adaptation for networking. results show that the adapted llm surpasses state-of-the-art algorithms by 10.1-36.6% for vp, 14.5-36.6% for abr, 6.8-41.3% for cjs, and also achieves superior generalization performance.",2024-02-04
"solitons, dispersive shock waves and noel fredrick smyth","saleh baqer, tim marchant, gaetano assanto, theodoros horikis, dimitri frantzeskakis","history and philosophy of physics","noel frederick smyth (nfs), a fellow of the australian mathematical society and a professor of nonlinear waves in the school of mathematics at the university of edinburgh, passed away on february 5, 2023. nfs was a prominent figure among applied mathematicians who worked on nonlinear wave theory in a broad range of areas. throughout his academic career, which spanned nearly forty years, nfs developed mathematical models, ideas, and techniques that have had a large impact on the understanding of wave motion in diverse media. his major research emphasis primarily involved the propagation of solitary waves, or solitons, and dispersive shock waves, or undular bores, in various media, including optical fibers, liquid crystals, shallow waters and atmosphere. several approaches he developed have proven effective in analyzing the dynamics and modulations of related wave phenomena. this tribute in the journal of wave motion aims to provide a brief biographical sketch of nfs, discuss his major research achievements, showcase his scientific competence, untiring mentorship and unwavering dedication, as well as share final thoughts from his former students, colleagues, friends, and family. the authors had a special connection with nfs on both on personal and professional levels and hold deep gratitude for him and his invaluable work. in recognition of his achievements in applied mathematics, wave motion hosts a special issue entitled ""modelling nonlinear wave phenomena: from theory to applications,"" which presents the recent advancements in this field.",2024-02-02
"yolino++: single-shot estimation of generic polylines for mapless automated diving","annika meyer, christoph stiller","computer vision and pattern recognition","in automated driving, highly accurate maps are commonly used to support and complement perception. these maps are costly to create and quickly become outdated as the traffic world is permanently changing. in order to support or replace the map of an automated system with detections from sensor data, a perception module must be able to detect the map features. we propose a neural network that follows the one shot philosophy of yolo but is designed for detection of 1d structures in images, such as lane boundaries. we extend previous ideas by a midpoint based line representation and anchor definitions. this representation can be used to describe lane borders, markings, but also implicit features such as centerlines of lanes. the broad applicability of the approach is shown with the detection performance on lane centerlines, lane borders as well as the markings both on highways and in urban areas. versatile lane boundaries are detected and can be inherently classified as dashed or solid lines, curb, road boundaries, or implicit delimitation.",2024-02-01
"comment on: was ada lovelace actually the first programmer?","thomas misa","history and philosophy of physics","comment on herbert bruderer's recent cacm contribution, providing additional citations to recent publications on ada lovelace and suggesting a correction to his conclusions.",2023-10-03
"quantum nonlocality: how does nature do it?","marian kupczynski","quantum physics","in his article in science, nicolas gisin claimed that quantum correlations emerge from outside space time. we explain that they are due to space time symmetries. this paper is a critical review of metaphysical conclusions found in many recent articles. it advocates the importance of contextuality, einstein causality and global symmetries. bell tests allow only rejecting probabilistic coupling provided by a local hidden variable model, but they do not justify metaphysical speculations about quantum nonlocality and objects which know about each other state, even when separated by large distances. the violation of bell inequalities in physics and in cognitive science can be explained using the notion of bohr contextuality. if contextual variables, describing varying experimental contexts, are correctly incorporated into a probabilistic model, then the bell and chsh inequalities cannot be proven and nonlocal correlations may be explained in an intuitive way. we also elucidate the meaning of statistical independence assumption incorrectly called free choice, measurement independence or no conspiracy. since correlation does not imply causation, the violation of statistical independence should be called contextuality and it does not restrict the experimenter freedom of choice. therefore, contrary to what is believed, closing the freedom of choice loophole does not close the contextuality loophole.",2024-02-01
"the smoke of zaanen","philip w. phillips","history and philosophy of physics","theoretical physics suffered a major loss with the death of my dear friend jan zaanen on january 18. this note is my remembrance of him.",2024-01-31
"the development of the concept of exchange forces in the 1930s: close encounters between europe and japan and the birth of nuclear theory","marco di mauro, salvatore esposito, adele naddeo","history and philosophy of physics","the onset and the development of the concept of exchange force in quantum physics are historically reconstructed, starting from heisenberg's seminal contributions in 1926 and going through the great developments in nuclear physics, which allowed the emergence of the idea of force mediating virtual quanta. although most of such work was performed in europe, the last and decisive effort in this long path was carried out by japanese scientists in the 1930s. this is the main focus of the present work, which retraces the achievements of yukawa and tomonaga, whose results and mutual interactions are carefully analyzed and related to those of european physicists.",2024-01-31
"i think, therefore i am: benchmarking awareness of large language models using awarebench","yuan li, yue huang, yuli lin, siyuan wu, yao wan, lichao sun","computation and language","do large language models (llms) exhibit any forms of awareness similar to humans? in this paper, we introduce awarebench, a benchmark designed to evaluate awareness in llms. drawing from theories in psychology and philosophy, we define awareness in llms as the ability to understand themselves as ai models and to exhibit social intelligence. subsequently, we categorize awareness in llms into five dimensions, including capability, mission, emotion, culture, and perspective. based on this taxonomy, we create a dataset called awareeval, which contains binary, multiple-choice, and open-ended questions to assess llms' understandings of specific awareness dimensions. our experiments, conducted on 13 llms, reveal that the majority of them struggle to fully recognize their capabilities and missions while demonstrating decent social intelligence. we conclude by connecting awareness of llms with ai alignment and safety, emphasizing its significance to the trustworthy and ethical development of llms. our dataset and code are available at this https url.",2024-01-31
"tracing quantum correlations back to collective interferences","ming ji, jonte r. hance, holger f. hofmann","quantum physics","in this paper, we investigate the possibility of explaining nonclassical correlations between two quantum systems in terms of quantum interferences between collective states of the two systems. we achieve this by mapping the relations between different measurement contexts in the product hilbert space of a pair of two-level systems onto an analogous sequence of interferences between paths in a single-particle interferometer. the paradoxical relations between different measurement outcomes can then be traced to the distribution of probability currents in the interferometer. we show that the relation between probability currents and correlations can be represented by continuous conditional (quasi)probability currents through the interferometer, given by weak values; the violation of the noncontextual assumption is expressed by negative conditional currents in some of the paths. since negative conditional currents correspond to the assignment of negative conditional probabilities to measurements results in different measurement contexts, the necessity of such negative probability currents represents a failure of noncontextual local realism. our results help to explain the meaning of nonlocal correlations in quantum mechanics, and support feynman's claim that interference is the origin of all quantum phenomena.",2024-01-30
"the physicists philosophy of physics","p. j. e. peebles","history and philosophy of physics","i argue that research in physics operates under an implicit community philosophy, and i offer a definition i think physicists would accept, by and large. i compare this definition to what philosophers, sociologists, and historians of science, with physicists, say we are doing.",2024-01-29
"robustness and the event horizon telescope: the case of the first image of m87*","juliusz doboszewski, jamee elder","history and philosophy of physics","we examine the justification for taking the event horizon telescope's famous 2019 image to be a reliable representation of the region surrounding a black hole. we argue that it takes the form of a robustness argument, with the resulting image being robust across variation in a range of data-analysis pipelines. we clarify the sense of ""robustness"" operating here and show how it can account for the reliability of astrophysical inferences, even in cases -- like the eht -- where these inferences are based on experiments that are (for all practical purposes) unique. this has consequences far beyond the 2019 image.",2024-01-29
"the combination problem for relational quantum mechanics","emily adlam","quantum physics","this article uses the existing literature on the panpsychist combination problem as a starting point to think about how to address a structurally similar combination problem in relational quantum mechanics. i note some similarities and differences between the two problems, and i consider various proposed solutions to the panpsychist problem, assessing the prospects for a similar solution in the context of rqm. i argue that overall the prospects for solving rqm's combination problem look better for rqm with cross-perspective links than for orthodox versions of rqm.",2024-01-28
"pannekoek's galaxy","pieter c. van der kruit","history and philosophy of physics","antonie (anton) pannekoek (1873-1960) is remembered as one of the initiators of the field of stellar atmospheres. a second part of his research concerned galactic astronomy. he was convinced that the sidereal system was built up of clouds of stars in a smooth, low-density stratum. in addition there were dark clouds together with streaks with little or no extinction in between. pannekoek looked at bright star clouds and estimated their distance from their contribution to star counts. he found values of tens of kpc, which would mean their distribution was similar in extent to that of shapleys globular cluster system. later he had to reduce his distance by a factor over two, and later still retract the method. he developed a rigorous method of estimating distances of dark clouds from modeling star counts off and on the cloud, preceding wolf's quick and dirty method. he should have received more credit for this. he started isophotal maps of the northern and southern milky way, first from visual observations, later from photographic surface photometry using out-of-focus exposures. i compare pannekoeks maps with detailed photographic surface photometry of the south by the group in bochum and to the almost all-sky mapping by the pioneer 10 spacecraft, free of zodiacal light, from beyond the asteroid belt. this shows panneloeks maps to be surprisingly accurate. the legacy of pannekoek in the area of galactic research consists of his mapping of the structure of the nearby part of the galaxy, the distances of dark clouds, and isophotal maps of the milky way. his other contributions turned out inconclusive or wrong as a result of his conviction, resulting from his many years of observing and mapping the milky way, that the nearby distribution is characterized primarily by more or less isolated clouds of stars and by dust restricted to isolated dark clouds and streaks.",2024-01-27
"en route to reduction: lorentzian manifolds and causal sets","jeremy butterfield","history and philosophy of physics","i present aspects of causal set theory (a research programme in quantum gravity) as being en route to achieving a reduction of lorentzian geometry to causal sets. i take reduction in philosophers' sense; and i argue that the prospects are good for there being a reduction of the type envisaged by nagel. (i also discuss the prospects for the stronger functionalist variant of nagelian reduction, that was formulated by lewis.) one main theme will be causal set theory's use of a physical scale (viz. the planck scale) to formulate how it recovers a lorentzian manifold. this use illustrates various philosophical topics relevant to reduction, such as limiting relations between theories, and the role of analogy. i also emphasise causal set theory's probabilistic method, viz. poisson sprinkling: which is used both for formulating the reduction and for exploring its prospects.",2024-01-27
"distributionally robust optimization and robust statistics","jose blanchet, jiajin li, sirui lin, xuhui zhang","methodology","we review distributionally robust optimization (dro), a principled approach for constructing statistical estimators that hedge against the impact of deviations in the expected loss between the training and deployment environments. many well-known estimators in statistics and machine learning (e.g. adaboost, lasso, ridge regression, dropout training, etc.) are distributionally robust in a precise sense. we hope that by discussing the dro interpretation of well-known estimators, statisticians who may not be too familiar with dro may find a way to access the dro literature through the bridge between classical results and their dro equivalent formulation. on the other hand, the topic of robustness in statistics has a rich tradition associated with removing the impact of contamination. thus, another objective of this paper is to clarify the difference between dro and classical statistical robustness. as we will see, these are two fundamentally different philosophies leading to completely different types of estimators. in dro, the statistician hedges against an environment shift that occurs after the decision is made; thus dro estimators tend to be pessimistic in an adversarial setting, leading to a min-max type formulation. in classical robust statistics, the statistician seeks to correct contamination that occurred before a decision is made; thus robust statistical estimators tend to be optimistic leading to a min-min type formulation.",2024-01-26
"deconstructing denoising diffusion models for self-supervised learning","xinlei chen, zhuang liu, saining xie, kaiming he","computer vision and pattern recognition","in this study, we examine the representation learning abilities of denoising diffusion models (ddm) that were originally purposed for image generation. our philosophy is to deconstruct a ddm, gradually transforming it into a classical denoising autoencoder (dae). this deconstructive procedure allows us to explore how various components of modern ddms influence self-supervised representation learning. we observe that only a very few modern components are critical for learning good representations, while many others are nonessential. our study ultimately arrives at an approach that is highly simplified and to a large extent resembles a classical dae. we hope our study will rekindle interest in a family of classical methods within the realm of modern self-supervised learning.",2024-01-25
"200 years of the navier-stokes equation","sylvio r. bistafa","history and philosophy of physics","the year 2022 marked the 200th anniversary of the first appearance of the navier-stokes equation, a landmark in fluid dynamics introduced by claude-louis navier in 1822. this equation revolutionized the understanding of fluid motion by incorporating viscosity and friction into the equations, expanding their applicability beyond idealized fluids. in this manuscript, we explore the historical development of the navier-stokes equation and its profound impact on fluid dynamics over the past two centuries. from navier's initial insights to george stokes' experimental validations and subsequent contributions by other scientists, we trace the evolution of this equation. we also delve into its practical applications, including its role in the development of computational fluid dynamics. the navier-stokes equation has played a pivotal role in advancing our understanding of fluid behavior, making it a cornerstone of modern science and engineering.",2023-10-14
"quantum collapse as undecidable proposition in an everettian multiverse","fabrizio tamburini, ignazio licata","quantum physics","our representation of the universe is built with sequences of symbols, numbers, operators, rules and undecidable propositions defining our mathematical truths, represented either by classical, quantum and probabilistic turing machines containing intrinsic randomness. each representation is at all effects a physical subset of the universe, a metastructure of events in space and time, which actively participate to the evolution of the universe as we are internal observers. the evolution is a deterministic sequence of local events, quantum measurements, originated from the local wavefunction collapse of the complementary set of the observers that generate the local events in the universe. with these assumptions, the universe and its evolution are described in terms of a semantically closed structure without a global object-environment loss of decoherence as a von neumann's universal constructor with a semantical abstract whose structure cannot be decided deterministically a-priori from an internal observer. in a semantically closed structure the realization of a specific event writing the semantical abstract of the constructor is a problem that finds a ""which way"" for the evolution of the universe in terms of a choice of the constructor's state in a metastructure, the many-world everett scenario from the specific result of a quantum measurement, a classical gödel undecidable proposition for an internal observer, exposing the limits of our description and possible simulation of the universe.",2024-01-24
"joseph wolstenholme and the trigonometry of tetrahedra","daniil rudenko","history and philosophy of physics","we describe the results in the trigonometry of tetrahedra obtained by joseph wolstenholme in the last few years of his life. 'the late professor wolstenholme, m.a., sc.d., shortly before his death, handed to me a scrap of paper, on which he had hastily scratched the following equation in tetrahedra, saying he had proved it ...' (richardson, 1897).",2024-01-24
"conservation principles in aqual","clara bradley, james owen weatherall","history and philosophy of physics","we consider conservation of momentum in aqual, a field-theoretic extension to modified newtonian dynamics (mond). we show that while there is a sense in which momentum is conserved, it is only if momentum is attributed to the gravitational field, and thus newton's third law fails as usually understood. we contrast this situation with that of newtonian gravitation on a field theoretic formulation. we then briefly discuss the situation in teves, a relativistic theory that has aqual as a classical limit.",2024-01-23
"ai, insurance, discrimination and unfair differentiation. an overview and research agenda","marvin s. l. van bekkum, frederik j. zuiderveen borgesius","computers and society","insurers increasingly use ai. we distinguish two situations in which insurers use ai: (i) data-intensive underwriting, and (ii) behaviour-based insurance. (i) first, insurers can use ai for data analysis to assess risks: data-intensive underwriting. underwriting is, in short, calculating risks and amending the insurance premium accordingly. (ii) second, insurers can use ai to monitor the behaviour of consumers in real-time: behaviour-based insurance. for example, some car insurers give a discount if a consumer agrees to being tracked by the insurer and drives safely. while the two trends bring many advantages, they may also have discriminatory effects. this paper focuses on the following question. which discrimination-related effects may occur if insurers use data-intensive underwriting and behaviour-based insurance? we focus on two types of discrimination-related effects: discrimination and other unfair differentiation. (i) discrimination harms certain groups who are protected by non-discrimination law, for instance people with certain ethnicities. (ii) unfair differentiation does not harm groups that are protected by non-discrimination law, but it does seem unfair. we introduce four factors to consider when assessing the fairness of insurance practices. the paper builds on literature from various disciplines including law, philosophy, and computer science.",2024-01-22
"introduction to the second edition of ""the supersymmetric world''","m. shifman","history and philosophy of physics","the first edition of this book was released in 2000, just before the symposium ``thirty years of supersymmetry'' was held at the william i. fine theoretical physics institute (ftpi) of the university of minnesota. founders and trailblazers of supersymmetry descended on ftpi, as well as a large crowd of younger theorists deeply involved in research in this area. since then 23 years have elapsed and significant changes happened in supersymmetry (susy). its history definitely needs an update. such an update is presented below. the second edition of the revised collection will be released in 2024.",2024-01-19
"biography of the french astronomer henri camichel","emmanuel davoust","history and philosophy of physics","henri camichel was an astronomer at pic du midi observatory, where he contributed to the study of planets of the solar system and their satellites with audouin dollfus and his team. in 1961, with charles boyer, he found that the upper atmosphere of venus had a counter-clockwise rotation of four days, which was later confirmed by space probes, as were the team's accurate measurements of the diameters of planets. he was also an instrumentalist, and contributed to the maintenance and development of the telescopes, notably the 2-meter telescope and focal instruments at pic du midi observatory.",2023-10-12
"verification and enforcement of strong state-based opacity for discrete-event systems","xiaoguang han, kuize zhang, zhiwu li","formal languages and automata theory","in this paper, we investigate the verification and enforcement of strong state-based opacity (sbo) in discrete-event systems modeled as partially-observed (nondeterministic) finite-state automata, including strong k-step opacity (k-sso), strong current-state opacity (scso), strong initial-state opacity (siso), and strong infinite-step opacity (inf-sso). they are stronger versions of four widely-studied standard opacity notions, respectively. we firstly propose a new notion of k-sso, and then we construct a concurrent-composition structure that is a variant of our previously-proposed one to verify it. based on this structure, a verification algorithm for the proposed notion of k-sso is designed. also, an upper bound on k in the proposed k-sso is derived. secondly, we propose a distinctive opacity-enforcement mechanism that has better scalability than the existing ones (such as supervisory control). the basic philosophy of this new mechanism is choosing a subset of controllable transitions to disable before an original system starts to run in order to cut off all its runs that violate a notion of strong sbo of interest. accordingly, the algorithms for enforcing the above-mentioned four notions of strong sbo are designed using the proposed two concurrent-composition structures. in particular, the designed algorithm for enforcing inf-sso has lower time complexity than the existing one in the literature, and does not depend on any assumption. finally, we illustrate the applications of the designed algorithms using examples.",2024-01-18
"stolzenberg's ""the holy office in the republic of letters"" revisited: on an astronomical diagram and whether the papacy tacitly permitted the circulation of an explicitly copernican book in 1660","christopher m. graney","history and philosophy of physics","did the papacy tacitly permit the circulation of an explicitly copernican book in 1660? one scholar has recently argued that it did. a close analysis of a unique illustration from that book, andreas cellarius's atlas harmonia macrocosmica, illuminates this argument. this is because the illustration, a diagram showing the relative sizes of the sun, moon, planets, and stars, was among the material reviewed (at the request of the book's publisher) by the holy office prior to the book's publication and was pro-copernican.",2024-01-18
"exact real search: formalised optimisation and regression in constructive univalent mathematics","todd waugh ambridge","logic in computer science","the real numbers are important in both mathematics and computation theory. computationally, real numbers can be represented in several ways; most commonly using inexact floating-point data-types, but also using exact arbitrary-precision data-types which satisfy the expected mathematical properties of the reals. this thesis is concerned with formalising properties of certain types for exact real arithmetic, as well as utilising them computationally for the purposes of search, optimisation and regression. we develop, in a constructive and univalent type-theoretic foundation of mathematics, a formalised framework for performing search, optimisation and regression on a wide class of types. this framework utilises martín escardó's prior work on searchable types, along with a convenient version of ultrametric spaces -- which we call closeness spaces -- in order to consistently search certain infinite types using the functional programming language and proof assistant agda. we formally define and prove the convergence properties of type-theoretic variants of global optimisation and parametric regression, problems related to search from the literature of analysis. as we work in a constructive setting, these convergence theorems yield computational algorithms for correct optimisation and regression on the types of our framework. importantly, we can instantiate our framework on data-types from the literature of exact real arithmetic, allowing us to perform our variants of search, optimisation and regression on ternary signed-digit encodings of the real numbers, as well as a simplified version of hans-j. boehm's functional encodings of real numbers. furthermore, we contribute to the extensive work on ternary signed-digits by formally verifying the definition of certain exact real arithmetic operations using the escardó-simpson interval object specification of compact intervals.",2024-01-17
"concept alignment","sunayana rane, polyphony j. bruna, ilia sucholutsky, christopher kello, thomas l. griffiths","machine learning","discussion of ai alignment (alignment between humans and ai systems) has focused on value alignment, broadly referring to creating ai systems that share human values. we argue that before we can even attempt to align values, it is imperative that ai systems and humans align the concepts they use to understand the world. we integrate ideas from philosophy, cognitive science, and deep learning to explain the need for concept alignment, not just value alignment, between humans and machines. we summarize existing accounts of how humans and machines currently learn concepts, and we outline opportunities and challenges in the path towards shared concepts. finally, we explain how we can leverage the tools already being developed in cognitive science and ai research to accelerate progress towards concept alignment.",2024-01-09
"cellular automaton ontology, bits, qubits, and the dirac equation","hans-thomas elze","quantum physics","cornerstones of the cellular automaton interpretation of quantum mechanics are its ontological states that evolve by permutations, in this way never creating would-be quantum mechanical superposition states. we review and illustrate this with a classical ising spin chain. it is shown that it can be related to the weyl equation in the continuum limit. yet, the model of discrete spins or bits unavoidably becomes a model of qubits by generating superpositions, if only slightly deformed. we study modifications of its signal velocity which, however, do not relate to mass terms. to incorporate the latter, we consider the dirac equation in 1+1 dimensions and sketch an underlying discrete deterministic ""necklace of necklaces"" automaton that qualifies as ontological.",2024-01-16
"non-archimedean plectic jacobians","michele fornea, lennart gehrmann","number theory","plectic stark-heegner points were recently introduced to explore the arithmetic of higher rank elliptic curves: the concept was inspired by nekovář and scholl's plectic philosophy, while the construction is based on bertolini and darmon's groundbreaking use of the $p$-adic uniformization of shimura curves to study the birch-swinnerton-dyer conjecture. in this note we give a geometric interpretation of plectic heegner points using the non-archimedean uniformization of higher-dimensional quaternionic shimura varieties. to this end, we define and study a plectic jacobian functor from a category of mumford varieties to topological groups extending the classical jacobian functor on mumford curves.",2024-01-15
"why we care (about quantum machine learning)","richard a. wolf","physics and society","quantum machine learning has received tremendous amounts of attention in the last ten years, and this trend is on the rise. despite its developments being currently limited to either theoretical statements and formal proofs or small-scale noisy experiments and classical simulations, this field of quantum technologies has been consistently standing in the spotlight. moreover, the locus of attention seems to have been skewed towards three central questions: ""can we beat classical computers?"", ""how?"" and ""when?"". in this work, i argue that focus on quantum machine learning stems from a wide range of factors, some of which lie outside the discipline itself. based on both recent and key publications on the subject as well as general audience sources, i give a brief overview of the core questions being raised in quantum machine learning and propose a socio-epistemologic interpretation of the motivations behind those and interplay between them.",2024-01-15
"reliability and interpretability in science and deep learning","luigi scorzato","artificial intelligence","in recent years, the question of the reliability of machine learning (ml) methods has acquired significant importance, and the analysis of the associated uncertainties has motivated a growing amount of research. however, most of these studies have applied standard error analysis to ml models, and in particular deep neural network (dnn) models, which represent a rather significant departure from standard scientific modelling. it is therefore necessary to integrate the standard error analysis with a deeper epistemological analysis of the possible differences between dnn models and standard scientific modelling and the possible implications of these differences in the assessment of reliability. this article offers several contributions. first, it emphasises the ubiquitous role of model assumptions (both in ml and traditional science) against the illusion of theory-free science. secondly, model assumptions are analysed from the point of view of their (epistemic) complexity, which is shown to be language-independent. it is argued that the high epistemic complexity of dnn models hinders the estimate of their reliability and also their prospect of long-term progress. some potential ways forward are suggested. thirdly, this article identifies the close relation between a model's epistemic complexity and its interpretability, as introduced in the context of responsible ai. this clarifies in which sense, and to what extent, the lack of understanding of a model (black-box problem) impacts its interpretability in a way that is independent of individual skills. it also clarifies how interpretability is a precondition for assessing the reliability of any model, which cannot be based on statistical analysis alone. this article focuses on the comparison between traditional scientific models and dnn models. but, random forest and logistic regression models are also briefly considered.",2024-01-14
"how quarks made their entrance into our worldview via cosmic rays and proton accelerators","jos engelen","history and philosophy of physics","sixty years ago gell-mann introduced, with a striking sense of caution, a new fundamental layer in the structure of matter. he christened the associated particles 'quarks', a name borrowed from the psychedelic flood of words of james joyce's novel finnegans wake. independently and simultaneously, zweig arrived at similar ideas. we outline the circumstances that led to the introduction of quarks.",2024-01-13
"the causal axioms of algebraic quantum field theory: a diagnostic","francisco calderón","mathematical physics","algebraic quantum field theory (aqft) puts forward three ""causal axioms"" that aim to characterize the theory as one that implements relativistic causation: the spectrum condition, microcausality, and primitive causality. in this paper, i aim to show, in a minimally technical way, that none of them fully explains the notion of causation appropriate for aqft because they only capture some of the desiderata for relativistic causation i state or because it is often unclear how each axiom implements its respective desideratum. after this diagnostic, i will show that a fourth condition, local primitive causality (lpc), fully characterizes relativistic causation in the sense of fulfilling all the relevant desiderata. however, it only encompasses the virtues of the other axioms because it is implied by them, as i will show from a construction by haag and schroer (1962). since the conjunction of the three causal axioms implies lpc and other important results in qft that lpc does not imply, and since lpc helps clarify some of the shortcomings of the three axioms, i advocate for a holistic interpretation of how the axioms characterize the causal structure of aqft against the strategy in the literature to rivalize the axioms and privilege one among them.",2024-01-12
"the effect of value-focused discussions on scientists' ethical decision making","tyler garcia, bill bridges, caitlin solis, caleb linville, wyatt jones, scott tanona, jonathan herington, james t. laverty","physics education","many scientists view science as value-free, despite the fact that both epistemic and non-epistemic values structure scientific inquiry. current ethics training usually focuses on transmitting knowledge about high-level ethical concepts or rules and is widely regarded as ineffective. we argue that ethics training will be more effective at improving ethical decision making if it focuses on connecting values to science. we pull from philosophy and psychology to define ethical decision making using the four component model. this model states that in order to make an ethical decision someone must consider four components: moral sensitivity, moral reasoning, moral motivation, and moral implementation. we formed a moderated fellowship of fourteen science faculty from different disciplines who met for ten sessions over the course of a year, where they discussed the values embedded in different scientific norms. we then conducted interviews before and after the year-long fellowship that involved guided reflection of scenarios where there was some kind of ethical misconduct where the scientific practice required value judgements (e.g using unpublished data in their own work). we looked at how the fellowship affected the scientists' ability to recognize ethical dimensions regarding the scenarios. we found that this fellowship improved moral sensitivity, but their moral reasoning does not improve. we outlined our approach on how to look at scientists' ethical decision making and made recommendations on how to improve our approach. this work can inform future ethical training to align better with what scientists value and introduce useful concepts from philosophy and psychology to education research in physics.",2024-01-11
"are language models more like libraries or like librarians? bibliotechnism, the novel reference problem, and the attitudes of llms","harvey lederman, kyle mahowald","computation and language","are llms cultural technologies like photocopiers or printing presses, which transmit information but cannot create new content? a challenge for this idea, which we call bibliotechnism, is that llms often generate entirely novel text. we begin (part i) with a sustained defense of bibliotechnism against this challenge showing how even entirely novel text may be meaningful only in a derivative sense, and arguing that, in particular, much novel text generated by llms is only derivatively meaningful. but we argue (part ii) that bibliotechnism faces a different, novel challenge, stemming from examples in which llms generate ""novel reference"", using novel names to refer to novel entities. such examples could be smoothly explained if llms were not cultural technologies but possessed a limited form of agency (beliefs, desires, and intentions). according to interpretationism in the philosophy of mind, a system has beliefs, desires and intentions if and only if its behavior is well explained by the hypothesis that it has such states. so, according to interpretationism, cases of novel reference provide evidence that llms have beliefs, desires, and intentions. given that interpretationism is a live hypothesis about the nature of these states, we suggest that cases of novel reference provide evidence that llms do have beliefs, desires, and intentions.",2024-01-10
"autobiographical notes of a physicist","n. david mermin","history and philosophy of physics","i describe aspects of my life in physics: the name i publish under, great physicists i have known, how i got into quantum foundations, what role i've played in it. my form is autobiographical, but my personal experience may illustrate what it was like being a physicist over the past 60 years. i offer some offbeat ways of thinking about some orthodox physics.",2024-01-09
"quantum mechanics without quantum potentials","adam brownstein","quantum physics","the issue of non-locality in quantum mechanics can potentially be resolved by considering relativistically covariant diffusion in four-dimensional spacetime. stochastic particles described by the klein-gordon equation are shown to undergo a classical diffusion process in spacetime coordinates, which is seen by transforming the quantum cauchy-momentum equations to a lagrangian frame of reference. since the quantum potential term is removed under this transformation, the equations for momentum propagation along particle trajectories assume a classical form. a local stochastic de broglie-bohm interpretation for the klein-gordon system can subsequently be derived. we also introduce the concept of momentum equivariance to replace the second-order bohm-newton equations of motion, which break down due to non-linear terms of the stochastic lagrangian derivative.",2024-01-08
"a dynamic programming interpretation of quantum mechanics","adam brownstein","quantum physics","we introduce a transformation of the quantum phase $s'=s+\frac{\hbar}{2}\log\rho$, which converts the deterministic equations of quantum mechanics into the lagrangian reference frame of stochastic particles. we show that the quantum potential can be removed from the transformed quantum hamilton-jacobi equations if they are solved as stochastic hamilton-jacobi-bellman equations. the system of equations provide a local description of quantum mechanics, which is enabled by the inherently retrocausal nature of stochastic hamilton-jacobi-bellman equations. we also investigate the stochastic transformation of the classical system, where is it shown that quantum mechanics with the quantum potential reduced by a factor of $\frac{1}{2}$ has a classical representation, which may have interesting implications. finally, we discuss the notion of a subsystem correspondence principle, which constrains the ontology of the total quantum system.",2024-01-08
"proof of the nernst heat theorem","josé-maría martín-olalla","classical physics","the nernst heat theorem is probed from purely thermodynamic arguments connected with the second law of thermodynamics, and alien to the vanishing of the specific heats, or to the unattainability of the zeroth isotherm. if the proof is accepted the second law of thermodynamics would extend its applicability and the third postulate of thermodynamics would be narrowed to the fact that the entropy of a finite-density, chemically homogeneous body must not be negative. -- -- se demuestra el teorema de nernst a partir de argumentos exclusivamente termodinámicos que se extraen del segundo principio, y que son ajenos a la anulación de los calores específicos o a la inaccesibilidad de la isoterma cero. si se acepta la demostración, entonces el segundo principio extendería su rango de aplicabilidad y el tercer principio quedaría reducido al hecho de que la entropía de un cuerpo de densidad finita y quimicamente homogéneo no puede ser negativa.",2024-01-08
"a gl(3) converse theorem via a ""beyond endoscopy'' approach","valentin blomer, wing hong leung","number theory","we give a new proof of the converse theorem for maass forms on ${\rm gl}(3)$ using a technique that is inspired by langlands' philosophy of ""beyond endoscopy"", thereby implementing these ideas for the first time in a higher rank setting.",2024-01-08
"a philosophical introduction to language models -- part i: continuity with classic debates","raphaël millière, cameron buckner","computation and language","large language models like gpt-4 have achieved remarkable proficiency in a broad spectrum of language-based tasks, some of which are traditionally associated with hallmarks of human intelligence. this has prompted ongoing disagreements about the extent to which we can meaningfully ascribe any kind of linguistic or cognitive competence to language models. such questions have deep philosophical roots, echoing longstanding debates about the status of artificial neural networks as cognitive models. this article -- the first part of two companion papers -- serves both as a primer on language models for philosophers, and as an opinionated survey of their significance in relation to classic debates in the philosophy cognitive science, artificial intelligence, and linguistics. we cover topics such as compositionality, language acquisition, semantic competence, grounding, world models, and the transmission of cultural knowledge. we argue that the success of language models challenges several long-held assumptions about artificial neural networks. however, we also highlight the need for further empirical investigation to better understand their internal mechanisms. this sets the stage for the companion paper (part ii), which turns to novel empirical methods for probing the inner workings of language models, and new philosophical questions prompted by their latest developments.",2024-01-08
"from the first observations of cosmic rays to the physics of relativistic nuclei","p.i. zarubin, a.a. zaitsev","history and philosophy of physics","research of cosmic rays at the physical institute of the ussr academy of sciences resulted in the construction of the jinr synchrophasotron. for this purpose the electrophysical laboratory of the ussr academy of sciences was founded in 1953, which became part of jinr in 1956 as the high energy laboratory. the initial milestones to develop experiments at the laboratory on the synchrophasotron are presented. leaders and key participants in the experiments are highlighted, as well as the lessons and results relevant today.",2024-01-06
"reysa bernson, the unconventional head of the first french planetarium","yael naze (uliege)","history and philosophy of physics","the first modern planetarium was presented in 1923 in jena, germany. very soon in the subsequent years, planetariums were installed in other parts of europe as well as in america. france, however, got its first planetarium only in 1937, for the world exhibition organized in paris. the team that took care of that planetarium was headed by a female amateur astronomer named reysa bernson. this choice might seem surprising, but it was not made at random, thanks to her never-ending astronomical activities at that time. this paper aims to bring back memories of this very active amateur astronomer of the 1920s and 1930s, and show the many ways in which astronomy was disseminated a century ago.",2024-01-04
"u-trustworthy models.reliability, competence, and confidence in decision-making","ritwik vashistha, arya farahi","machine learning","with growing concerns regarding bias and discrimination in predictive models, the ai community has increasingly focused on assessing ai system trustworthiness. conventionally, trustworthy ai literature relies on the probabilistic framework and calibration as prerequisites for trustworthiness. in this work, we depart from this viewpoint by proposing a novel trust framework inspired by the philosophy literature on trust. we present a precise mathematical definition of trustworthiness, termed $\mathcal{u}$-trustworthiness, specifically tailored for a subset of tasks aimed at maximizing a utility function. we argue that a model's $\mathcal{u}$-trustworthiness is contingent upon its ability to maximize bayes utility within this task subset. our first set of results challenges the probabilistic framework by demonstrating its potential to favor less trustworthy models and introduce the risk of misleading trustworthiness assessments. within the context of $\mathcal{u}$-trustworthiness, we prove that properly-ranked models are inherently $\mathcal{u}$-trustworthy. furthermore, we advocate for the adoption of the auc metric as the preferred measure of trustworthiness. by offering both theoretical guarantees and experimental validation, auc enables robust evaluation of trustworthiness, thereby enhancing model selection and hyperparameter tuning to yield more trustworthy outcomes.",2024-01-04
"sheaves of probability","owen d. biesel","probability","what does it mean for multiple agents' credence functions to be consistent with each other, if the agents have distinct but overlapping sets of evidence? mathematical philosopher michael titelbaum's rule, called generalized conditionalization (gc), sensibly requires each pair of agents to acquire identical credences if they updated on each other's evidence. however, gc allows for paradoxical arrangements of agent credences that we would not like to call consistent. we interpret gc as a gluing condition in the context of sheaf theory, and show that if we further assume that the agents' evidence is logically consistent then the sheaf condition is satisfied and the paradoxes are resolved.",2024-01-03
"does the hamiltonian determine the tensor product structure and the 3d space?","ovidiu cristinel stoica","quantum physics","it was proposed that the tensor product structure of the hilbert space is uniquely determined by the hamiltonian's spectrum, for most finite-dimensional cases satisfying certain conditions. i show that any such method would lead to infinitely many tensor product structures. the dimension of the space of solutions grows exponentially with the number of qudits. in addition, even if the result were unique, such a hamiltonian would not entangle subsystems. these results affect the proposals to recover the 3d space from the hamiltonian.",2024-01-03
"unification of the mwi formalism and bohmian mechanics for the ensembles of event universes in minkowski-like space","oded shor, felix benninger, andrei khrennikov","quantum physics","diversity of interpretations of quantum mechanics is often considered as a sign of foundational crisis. in this note we proceed towards unification the relational quantum mechanics of rovelli, bohmian mechanics, and many worlds interpretation on the basis so called dendrogramic holographic theory (dht). dht is based on the representation of observed events by dendrograms (finite trees) presenting observers subjective image of universe. dendrograms encode the relational hierarchy between events, in applications they are generated by clustering algorithms; an algorithm with the branching index p >1 generate p-adic trees. the infinite p-adic tree represents the ontic event universe. we consider an ensemble of observers performing observations on each other and representing them by p-adic trees. in such observers universe we introduce a kind of minkowski space structure, which is statistical by its nature. this model unites the observer/system discrepancy. measurements are performed by observers on observers. such observers universe is dynamically changing and is background independent since the space itself is emergent. and within this model, we unify the aforementioned interpretations.",2023-09-28
"design of a full-filed transmission x-ray microscope with 30nm resolution","keliang liao, qili he, panyun li, maohua song, peiping zhu","instrumentation and detectors","a full-field transmission hard x-ray microscope (txm) with 30nm resolution was designed and its prototype was constructed. the txm relies on a compact, high stiffness, low heat dissipation and low vibration design philosophy and utilizes fresnel zone plate (fzp) as imaging optics. the design of the txm was introduced in detail, including the optical layout, the parameters of the fzp, the mechanical design of the txm instrument. preliminary imaging result with 52nm spatial resolution was achieved.",2023-11-15
"understanding and interpretations of quantum mechanics","dong luo","history and philosophy of physics","taking heisenberg's and schrodinger's theories of quantum mechanics as his case study, de regt's contextual theory of understanding argues that recognizing qualitatively characteristic consequences of a theory t without performing exact calculations is a criterion for scientific understanding. from the perspective of this theory of understanding, the task of understanding quantum mechanics seems to have been achieved already or even finished. this appears to disagree with some physicists' attitude to the understanding of quantum mechanics in line with richard feynman's famous slogan ""i think i can safely say that nobody really understands quantum mechanics."" moreover, if the task of understanding quantum mechanics has been finished already, there would be a conflict between the contextual theory of understanding of quantum mechanics and interpretations of quantum mechanics.",2023-08-25
"minimalist market design: a framework for economists with policy aspirations","tayfun sönmez","general economics","earlier in my career, prevalent approaches in the emerging field of market design largely represented the experiences and perspectives of leaders who were commissioned to design or reform various institutions. since being commissioned for a similar task seemed unlikely for me as an aspiring design economist, i developed my own minimalist approach to market design. using the policy objectives of stakeholders, my approach creates a new institution from the existing one with minimal interference with its elements that compromise the objectives. minimalist market design initially evolved through my integrated research and policy efforts in school choice from 1997 to 2005 and in kidney exchange from 2003 to 2007. given its success in school choice and kidney exchange, i systematically followed this approach in many other, often unusual real-world settings. in recent years, my efforts in minimalist market design led to the 2021 reform of the us army's branching system for its cadets to military specialties, the adoption of reserve systems during the covid-19 pandemic for vaccine allocation in 15 states and therapies in 2 states, and the deployment of a highly efficient liver exchange system in türkiye. this same methodology also predicted the rescission of a 1995 supreme court judgment in india, resulting in countless litigations and interruptions of public recruitment for 25 years, as well as the mandates of its replacement. in this monograph, i describe the philosophy, evolution, and successful applications of minimalist market design, contrasting it with the mainstream paradigm for the field. in doing so, i also provide a paradigm for economists who want to influence policy and change institutions through their research.",2023-12-30
"principle interference in technical and scientific translation","mohammad ibrahim qani","computation and language","in this article, i will explore the nature of interference in translation, especially in technical and scientific texts, using a descriptivist approach. i will have a brief overview of the historical excursion of interference in technical and scientific translation. my aim is to explain this phenomenon and its causes with all its paradoxes, instead of simply condemning it as an example of supposedly bad translation. thus, i will focus on its status in the bibliography of translation, on the motives for and consequences of interference in specialized translation, as well as on the nature of the arguments given for and against this phenomenon. therefore the relationship between different societies has always been possible with the act of translation. when civilizations are examined throughout history, it is seen that the dissemination of knowledge among different societies has been achieved by translation. these societies have often become aware of the advancements in technology and science by means of translation. therefore; translation becomes very significant in technical contact between societies and humans. since the translation of technical texts is the preliminary scope of this thesis, it will be beneficial to have a brief look at the history of technical translation in the world.",2023-12-30
"the hamiltonian for entangled states cannot be additive","kent a. peacock","history and philosophy of physics","the assumption that the system hamiltonian for entangled states is additive is widely used in orthodox quantum no-signalling arguments. it is shown that additivity implies a contradiction with the assumption that the system being studied is entangled.",2023-12-30
"relativity and quantum theory: under the spell of today's paradigms","stefan weigert","history and philosophy of physics","thomas s. kuhn interprets the development of the (natural) sciences as a specific dynamical process. periods of piecemeal growth of knowledge based on widely accepted paradigms are interrupted by bursts of revolutionary changes which lead to new paradigms incommensurate with the earlier ones. this process is briefly illustrated by recalling the changes to classical physics brought about by einstein's theory of relativity on the one hand, and by quantum theory on the other. both theories represent fundamental paradigms of contemporary physics. they appear unshakable to the working physicist but according to kuhn their paradigmatic status is of a temporary nature only. does kuhn's framework help us to identify potential future revolutions?",2023-12-29
"the arrow of time in music -- revisiting the temporal structure of music with distinguishability and unique orientability as the anchor point","qi xu","sound","driven by the term ""the arrow of time"" as a general topic, the article develops a musical discussion by referring to the etymological origin of the term: philosophy (epistemology) and physics (thermodynamics). in particular, the article explores two specific conditions: distinguishability and unique orientability, from which the article derives respective musical propositions and case studies. for the distinguishability condition, the article focuses on the ""recurrence"" in music and tries to interpret bach's christmas oratorio from the perspective of ""birth/resurrection"". for the unique orientability condition, the article discusses the process of delaying the climax, thereby proposing ""ab-aab left-replication"" model, implying an organicist view by treating the temporal structure of music (e.g. form) as the product of a dynamic process: organic growth.",2023-12-28
"seti at fast in china","tong-jie zhang, bo-lun huang, jian-kang li, zhen-zhao tao, xiao-hang luan, zhi-song zhang, yu-chen wang","earth and planetary astrophysics","since the commencement of the first seti observation in 2019, china's search for extraterrestrial intelligence program has garnered momentum through domestic support and international collaborations. several observations targeting exoplanets and nearby stars have been conducted with the fast. in 2023, the introduction of the far neighbour project(fnp) marks a substantial leap forward, driven by the remarkable sensitivity of the fast telescope and some of the novel observational techniques. the fnp seeks to methodically detect technosignatures from celestial bodies, including nearby stars, exoplanetary systems, milky way globular clusters, and more. this paper provides an overview of the progress achieved by seti in china and offers insights into the distinct phases comprising the fnp. additionally, it underscores the significance of this project's advancement and its potential contributions to the field.",2023-12-28
"on the hole argument and the physical interpretation of general relativity","jaume de haro","history and philosophy of physics","einstein presented the hole argument against general covariance, understood as invariance with respect to a change of coordinates, as a consequence of his initial failure to obtain covariant equations that, in the weak static limit, contain newton's law. fortunately, about two years later, einstein returned to general covariance and found these famous equations of gravity. however, the rejection of his hole argument carries a totally different vision of space-time. its substantivalism notion, which is an essential ingredient in newtonian theory and also in his special theory of relativity, has to be replaced, following descartes and leibniz's relationalism, by a set of ""point-coincidences.""",2023-12-27
"understanding news creation intents: frame, dataset, and method","zhengjia wang, danding wang, qiang sheng, juan cao, silong su, yifan sun, beizhe hu, siyuan ma","computation and language","as the disruptive changes in the media economy and the proliferation of alternative news media outlets, news intent has progressively deviated from ethical standards that serve the public interest. news intent refers to the purpose or intention behind the creation of a news article. while the significance of research on news intent has been widely acknowledged, the absence of a systematic news intent understanding framework hinders further exploration of news intent and its downstream applications. to bridge this gap, we propose news intent (nint) frame, the first component-aware formalism for understanding the news creation intent based on research in philosophy, psychology, and cognitive science. within this frame, we define the news intent identification task and provide a benchmark dataset with fine-grained labels along with an efficient benchmark method. experiments demonstrate that nint is beneficial in both the intent identification task and downstream tasks that demand a profound understanding of news. this work marks a foundational step towards a more systematic exploration of news creation intents.",2023-12-27
"robustness verification for knowledge-based logic of risky driving scenes","xia wang, anda liang, jonathan sprinkle, taylor t. johnson","artificial intelligence","many decision-making scenarios in modern life benefit from the decision support of artificial intelligence algorithms, which focus on a data-driven philosophy and automated programs or systems. however, crucial decision issues related to security, fairness, and privacy should consider more human knowledge and principles to supervise such ai algorithms to reach more proper solutions and to benefit society more effectively. in this work, we extract knowledge-based logic that defines risky driving formats learned from public transportation accident datasets, which haven't been analyzed in detail to the best of our knowledge. more importantly, this knowledge is critical for recognizing traffic hazards and could supervise and improve ai models in safety-critical systems. then we use automated verification methods to verify the robustness of such logic. more specifically, we gather 72 accident datasets from this http url and organize them by state. further, we train decision tree and xgboost models on each state's dataset, deriving accident judgment logic. finally, we deploy robustness verification on these tree-based models under multiple parameter combinations.",2023-12-27
"multiwavelength observations of gamma ray bursts","rahul gupta","high energy astrophysical phenomena","gamma-ray bursts (grbs) are fascinating sources studied in modern astronomy. they are extremely luminous electromagnetic explosions in the universe observed from cosmological distances. these unique characteristics provide a marvellous chance to study the evolution of massive stars and probe the rarely explored early universe. in addition, the central source's compactness and the high bulk lorentz factor in grb's ultra-relativistic jets make them efficient laboratories for studying high-energy astrophysics. grbs are the only astrophysical sources observed in two distinct signals: gravitational and electromagnetic waves. grbs are believed to be produced from a ""fireball"" moving at a relativistic speed, launched by a fast-rotating black hole or magnetar. grbs emit radiation in two phases: the initial gamma/hard x-rays prompt emission, the duration of which ranges from a few seconds to hours, followed by the multi-wavelength and long-lived afterglow phase. based on the observed time frame of grb prompt emission, astronomers have generally categorized grbs into two groups: long (> 2 s) and short (< 2 s) bursts. despite the discovery of grbs in the late 1960s, their origin is still a great mystery. there are several open questions related to grbs, such as: what powers the grbs jets/central engine? what are the possible progenitors? what is the jet composition? what is the underlying emission process that gives rise to observed radiation? where and how does the energy dissipation occur in the outflow? how to solve the radiative efficiency problem? what are the possible causes of dark grbs and orphan afterglows? how to investigate the local environment of grbs? etc. in this thesis, we explored some of these open enigmas (progenitor, emission mechanisms, jet composition and environment) using multi-wavelength observations obtained using space and ground-based facilities.",2023-12-26
"limits and epistemological barriers to the human knowledge of the natural world","j. e. horvath, r.r. fernandes, t.p. idiart","history and philosophy of physics","the goal of this article is to give an overview of the current limitations and epistemological barriers in science and scientific philosophy from a very general point of view. we first list and define the types of knowledge nous, doxa and episteme, and the subject-observer and object(s) of study, to proceed showing the different types of barriers that difficult the knowledge of the physical world: limitations in the language, in the logic of the subject-observer. later, we discriminate between technological barriers, (temporary) limits and absolute epistemic barriers. the last type of limits are presented and discussed in some detail: the quantum of action, planck's scale and quantum gravity (showing the importance of the trans-planckian scale for structure formation), the cosmological horizon (a limit to the present observable universe) and the event horizons (disconnecting the inside of some spacetimes from the rest of the universe). we argue that physical problems in which absolute barriers seem to determine the end of the attainable knowledge, are in fact amenable to be studied, at least indirectly.",2023-12-24
"the non-abelian aharonov-bohm effect","p. a. horvathy","high energy physics - theory","the scattering of a nucleon beam around a cylinder containing a non-abelian flux is studied. we confirm all the previsions of wu and yang. we consider the generalization to the gauge group $su(n)$, and derive a classification scheme. isospin precession is recovered also at the classical limit.",2023-12-26
"remembering nino boccara (1931--2018)","henryk fukś","history and philosophy of physics","in commemoration of the fifth anniversary since nino boccara's departure, this article offers some personal recollections and provides insight into his life and accomplishments. detailed bibliography of his works is included together with commentary highlighting his major achievements.",2023-12-13
"fisher's underworld and the behavioral-statistical reliability balance in scientific inference","ryan martin","statistics theory","that science and other domains are now largely data-driven means virtually unlimited opportunities for statisticians. with great power comes responsibility, so it's imperative that statisticians ensure that the methods being developing to solve these problems are reliable. but reliable in what sense? this question is problematic because different notions of reliability correspond to distinct statistical schools of thought, each with their own philosophy and methodology, often giving different answers in applications. to achieve the goal of reliably solving modern problems, i argue that a balance in the behavioral-statistical priorities is needed. towards this, i make use of fisher's ""underworld of probability"" to motivate a new property called invulnerability that, roughly, requires the statistician to avoid the risk of losing money in a long-run sense. then i go on to make connections between invulnerability and the more familiar behaviorally- and statistically-motivated notions, namely coherence and (frequentist-style) validity.",2023-12-22
"a non-causal reconceptualization of quantum field theory","christopher thron","general physics","quantum field theory currently has a single standard mathematical characterization (the standard model), but no single accepted conceptual framework to interpret the mathematics. many of these conceptualizations rely on intuitive concepts carried over from classical physics (such as ""particle"" and ""causality""). in this paper, instead of relying on classical concepts we attempt to infer a conceptualization directly from the mathematics. this reconceptualization leads to a physical reinterpretation of the paths involved in the standard model's action integral as traces of an accumulative process that occurs within an ""extraverse"", of which our observable spacetime is a single ""slice"". we briefly outline a rigorous mathematical model which validates the physical reinterpretation, and leads to predictions that are potentially verifiable by experiment. we contrast our model with other popular interpretations of quantum mechanics. we describe some of the metaphysical consequences of our proposed perspective. finally we present some speculations about an alternative approach that could possibly lead to a more satisfying, intuitively-graspable theory.",2023-12-18
"on the tensorial structure of general covariant quantum systems","gabriel m.carral, iñaki garay, francesca vidotto","general relativity and quantum cosmology","the definition of a quantum system requires a hilbert space, a way to define the dynamics, and an algebra of observables. the structure of the observable algebra is related to a tensor product decomposition of the hilbert space and represents the composition of the system by subsystems. it has been remarked that the hamiltonian may determine this tensor product structure. here we observe that this fact may lead to questionable consequences in some cases, and does extend to the more general background-independent case, where the hamiltonian is replaced by a hamiltonian constraint. these observations reinforces the idea that specifying the observables and the way they interplay with the dynamics, is essential to define a quantum theory. we also reflect on the general role that system decomposition has in the quantum theory.",2023-12-20
"explainable artificial intelligence approaches for brain-computer interfaces: a review and design space","param rajpura, hubert cecotti, yogesh kumar meena","human-computer interaction","this review paper provides an integrated perspective of explainable artificial intelligence techniques applied to brain-computer interfaces. bcis use predictive models to interpret brain signals for various high-stake applications. however, achieving explainability in these complex models is challenging as it compromises accuracy. the field of xai has emerged to address the need for explainability across various stakeholders, but there is a lack of an integrated perspective in xai for bci (xai4bci) literature. it is necessary to differentiate key concepts like explainability, interpretability, and understanding in this context and formulate a comprehensive framework. to understand the need of xai for bci, we pose six key research questions for a systematic review and meta-analysis, encompassing its purposes, applications, usability, and technical feasibility. we employ the prisma methodology -- preferred reporting items for systematic reviews and meta-analyses to review (n=1246) and analyze (n=84) studies published in 2015 and onwards for key insights. the results highlight that current research primarily focuses on interpretability for developers and researchers, aiming to justify outcomes and enhance model performance. we discuss the unique approaches, advantages, and limitations of xai4bci from the literature. we draw insights from philosophy, psychology, and social sciences. we propose a design space for xai4bci, considering the evolving need to visualize and investigate predictive model outcomes customised for various stakeholders in the bci development and deployment lifecycle. this paper is the first to focus solely on reviewing xai4bci research articles. this systematic review and meta-analysis findings with the proposed design space prompt important discussions on establishing standards for bci explanations, highlighting current limitations, and guiding the future of xai in bci.",2023-12-20
"robust machine learning by transforming and augmenting imperfect training data","elliot creager","machine learning","machine learning (ml) is an expressive framework for turning data into computer programs. across many problem domains -- both in industry and policy settings -- the types of computer programs needed for accurate prediction or optimal control are difficult to write by hand. on the other hand, collecting instances of desired system behavior may be relatively more feasible. this makes ml broadly appealing, but also induces data sensitivities that often manifest as unexpected failure modes during deployment. in this sense, the training data available tend to be imperfect for the task at hand. this thesis explores several data sensitivities of modern machine learning and how to address them. we begin by discussing how to prevent ml from codifying prior human discrimination measured in the training data, where we take a fair representation learning approach. we then discuss the problem of learning from data containing spurious features, which provide predictive fidelity during training but are unreliable upon deployment. here we observe that insofar as standard training methods tend to learn such features, this propensity can be leveraged to search for partitions of training data that expose this inconsistency, ultimately promoting learning algorithms invariant to spurious features. finally, we turn our attention to reinforcement learning from data with insufficient coverage over all possible states and actions. to address the coverage issue, we discuss how causal priors can be used to model the single-step dynamics of the setting where data are collected. this enables a new type of data augmentation where observed trajectories are stitched together to produce new but plausible counterfactual trajectories.",2023-12-19
"beyond fairness: alternative moral dimensions for assessing algorithms and designing systems","kimi wenzel, geoff kaufman, laura dabbish","computers and society","the ethics of artificial intelligence (ai) systems has risen as an imminent concern across scholarly communities. this concern has propagated a great interest in algorithmic fairness. large research agendas are now devoted to increasing algorithmic fairness, assessing algorithmic fairness, and understanding human perceptions of fairness. we argue that there is an overreliance on fairness as a single dimension of morality, which comes at the expense of other important human values. drawing from moral psychology, we present five moral dimensions that go beyond fairness, and suggest three ways these alternative dimensions may contribute to ethical ai development.",2023-12-19
"the dsa transparency database: auditing self-reported moderation actions by social media","amaury trujillo, tiziano fagni, stefano cresci","social and information networks","since september 2023, the digital services act (dsa) obliges large online platforms to submit detailed data on each moderation action they take within the european union (eu) to the dsa transparency database. from its inception, this centralized database has sparked scholarly interest as an unprecedented and potentially unique trove of data on real-world online moderation. here, we thoroughly analyze all 353.12m records submitted by the eight largest social media platforms in the eu during the first 100 days of the database. specifically, we conduct a platform-wise comparative study of their: volume of moderation actions, grounds for decision, types of applied restrictions, types of moderated content, timeliness in undertaking and submitting moderation actions, and use of automation. furthermore, we systematically cross-check the contents of the database with the platforms' own transparency reports. our analyses reveal that (i) the platforms adhered only in part to the philosophy and structure of the database, (ii) the structure of the database is partially inadequate for the platforms' reporting needs, (iii) the platforms exhibited substantial differences in their moderation actions, (iv) a remarkable fraction of the database data is inconsistent, (v) the platform x (formerly twitter) presents the most inconsistencies. our findings have far-reaching implications for policymakers and scholars across diverse disciplines. they offer guidance for future regulations that cater to the reporting needs of online platforms in general, but also highlight opportunities to improve and refine the database itself.",2023-12-16
"the instituto argentino de radioastronomía (iar): past, present, and future","gustavo e. romero","history and philosophy of physics","i present a brief review of the history of the instituto argentino de radioastronomía, a description of its current facilities and projects, and a view of his prospects for the future.",2023-12-15
"introspecting the happiness amongst university students using machine learning","sakshi ranjan, pooja priyadarshini, subhankar mishra","computers and society","happiness underlines the intuitive constructs of a specified population based on positive psychological outcomes. it is the cornerstone of the cognitive skills and exploring university student's happiness has been the essence of the researchers lately. in this study, we have analyzed the university student's happiness and its facets using statistical distribution charts; designing research questions. furthermore, regression analysis, machine learning, and clustering algorithms were applied on the world happiness dataset and university student's dataset for training and testing respectively. philosophy was the happiest department while sociology the saddest; average happiness score being 2.8 and 2.44 respectively. pearson coefficient of correlation was 0.74 for health. predicted happiness score was 5.2 and the goodness of model fit was 51%. train and test error being 0.52, 0.47 respectively. on a confidence interval(ci) of 5% p-value was least for campus environment(ce) and university reputation(ur) and maximum for extra-curricular activities(eca) and work balance(wb) (i.e. 0.184 and 0.228 respectively). rf with clustering got the highest accuracy(89%) and f score(0.98) and the least error(17.91%), hence turned out to be best for our study",2023-12-14
"assessing llms for moral value pluralism","noam benkler, drisana mosaphir, scott friedman, andrew smart, sonja schmer-galunder","computation and language","the fields of ai current lacks methods to quantitatively assess and potentially alter the moral values inherent in the output of large language models (llms). however, decades of social science research has developed and refined widely-accepted moral value surveys, such as the world values survey (wvs), eliciting value judgments from direct questions in various geographies. we have turned those questions into value statements and use nlp to compute to how well popular llms are aligned with moral values for various demographics and cultures. while the wvs is accepted as an explicit assessment of values, we lack methods for assessing implicit moral and cultural values in media, e.g., encountered in social media, political rhetoric, narratives, and generated by ai systems such as llms that are increasingly present in our daily lives. as we consume online content and utilize llm outputs, we might ask, which moral values are being implicitly promoted or undercut, or -- in the case of llms -- if they are intending to represent a cultural identity, are they doing so consistently? in this paper we utilize a recognizing value resonance (rvr) nlp model to identify wvs values that resonate and conflict with a given passage of output text. we apply rvr to the text generated by llms to characterize implicit moral values, allowing us to quantify the moral/cultural distance between llms and various demographics that have been surveyed using the wvs. in line with other work we find that llms exhibit several western-centric value biases; they overestimate how conservative people in non-western countries are, they are less accurate in representing gender for non-western countries, and portray older populations as having more traditional values. our results highlight value misalignment and age groups, and a need for social science informed technological solutions addressing value plurality in llms.",2023-12-08
"llamantino: llama 2 models for effective text generation in italian language","pierpaolo basile, elio musacchio, marco polignano, lucia siciliani, giuseppe fiameni, giovanni semeraro","computation and language","large language models represent state-of-the-art linguistic models designed to equip computers with the ability to comprehend natural language. with its exceptional capacity to capture complex contextual relationships, the llama (large language model meta ai) family represents a novel advancement in the field of natural language processing by releasing foundational models designed to improve the natural language understanding abilities of the transformer architecture thanks to their large amount of trainable parameters (7, 13, and 70 billion parameters). in many natural language understanding tasks, these models obtain the same performances as private company models such as openai chat-gpt with the advantage to make publicly available weights and code for research and commercial uses. in this work, we investigate the possibility of language adaptation for llama models, explicitly focusing on addressing the challenge of italian language coverage. adopting an open science approach, we explore various tuning approaches to ensure a high-quality text generated in italian suitable for common tasks in this underrepresented language in the original models' datasets. we aim to release effective text generation models with strong linguistic properties for many tasks that seem challenging using multilingual or general-purpose llms. by leveraging an open science philosophy, this study contributes to language adaptation strategies for the italian language by introducing the novel llamantino family of italian llms.",2023-12-15
